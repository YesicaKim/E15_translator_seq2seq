{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 번역기를 만들어 보자\n",
    "\n",
    "- 학습 목표\n",
    "    - 다양한 RNN의 구성을 알아보기\n",
    "    - 인코더와 디코더 구조의 필요성 이해하기\n",
    "    - 교사 강요(teacher forcing)의 원리 알기\n",
    "    - 훈련 단계와 추론 단계(inference)의 차이 알기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 번역기 만들기 (1) 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 화일을 데이터 프레임으로 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 178009\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72726</th>\n",
       "      <td>They've changed the rules.</td>\n",
       "      <td>Ils ont changé les règles.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122071</th>\n",
       "      <td>I think I look fat in these jeans.</td>\n",
       "      <td>Je pense que j'ai l'air grosse, dans ce jean.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110002</th>\n",
       "      <td>I am very sorry for what I said.</td>\n",
       "      <td>Je suis vraiment désolé pour ce que j'ai dit.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4822</th>\n",
       "      <td>You're fired.</td>\n",
       "      <td>Tu es viré.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60499</th>\n",
       "      <td>Do we have enough chairs?</td>\n",
       "      <td>A-t-on suffisamment de chaises ?</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       eng  \\\n",
       "72726           They've changed the rules.   \n",
       "122071  I think I look fat in these jeans.   \n",
       "110002    I am very sorry for what I said.   \n",
       "4822                         You're fired.   \n",
       "60499            Do we have enough chairs?   \n",
       "\n",
       "                                                  fra  \\\n",
       "72726                      Ils ont changé les règles.   \n",
       "122071  Je pense que j'ai l'air grosse, dans ce jean.   \n",
       "110002  Je suis vraiment désolé pour ce que j'ai dit.   \n",
       "4822                                      Tu es viré.   \n",
       "60499                A-t-on suffisamment de chaises ?   \n",
       "\n",
       "                                                       cc  \n",
       "72726   CC-BY 2.0 (France) Attribution: tatoeba.org #4...  \n",
       "122071  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "110002  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "4822    CC-BY 2.0 (France) Attribution: tatoeba.org #6...  \n",
       "60499   CC-BY 2.0 (France) Attribution: tatoeba.org #3...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "file_path = os.getenv('HOME')+'/aiffel/translator_seq2seq/data/fra.txt'\n",
    "lines = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.sample(5) #샘플 5개 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "세번째 열은 불필요하므로 제거하고, 훈련 데이터는 5만개의 샘플로 줄이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5632</th>\n",
       "      <td>I love nature.</td>\n",
       "      <td>J'adore la nature.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28086</th>\n",
       "      <td>You're the teacher.</td>\n",
       "      <td>C'est vous la professeur.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43512</th>\n",
       "      <td>It's easy to get lost.</td>\n",
       "      <td>On se perd facilement.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37374</th>\n",
       "      <td>No one's blaming you.</td>\n",
       "      <td>Personne ne vous fait de reproche.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13705</th>\n",
       "      <td>Are you my enemy?</td>\n",
       "      <td>Es-tu mon ennemi ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          eng                                 fra\n",
       "5632           I love nature.                  J'adore la nature.\n",
       "28086     You're the teacher.           C'est vous la professeur.\n",
       "43512  It's easy to get lost.              On se perd facilement.\n",
       "37374   No one's blaming you.  Personne ne vous fait de reproche.\n",
       "13705       Are you my enemy?                  Es-tu mon ennemi ?"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines[['eng', 'fra']][:50000] # 5만개 샘플 사용\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seq2seq 동작을 위해서 디코더의 입력과 예측에는 시작 토큰 <sos>와 종료 토큰 <eos>가 필요합니다. 이번에는 각각 \\t와 \\n을 사용하겠습니다. 두 토큰을 추가해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 50000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38198</th>\n",
       "      <td>They lost everything.</td>\n",
       "      <td>\\t Ils ont tout perdu. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7712</th>\n",
       "      <td>He looks young.</td>\n",
       "      <td>\\t Il a l'air jeune. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42629</th>\n",
       "      <td>I usually get up at 8.</td>\n",
       "      <td>\\t Je me lève généralement à huit heures. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>We'll try.</td>\n",
       "      <td>\\t Nous tenterons. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21198</th>\n",
       "      <td>The street is wet.</td>\n",
       "      <td>\\t La rue est mouillée. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          eng                                           fra\n",
       "38198   They lost everything.                     \\t Ils ont tout perdu. \\n\n",
       "7712          He looks young.                       \\t Il a l'air jeune. \\n\n",
       "42629  I usually get up at 8.  \\t Je me lève généralement à huit heures. \\n\n",
       "1027               We'll try.                         \\t Nous tenterons. \\n\n",
       "21198      The street is wet.                    \\t La rue est mouillée. \\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰 추가\n",
    "sos_token = '\\t'\n",
    "eos_token = '\\n'\n",
    "lines.fra = lines.fra.apply(lambda x : '\\t '+ x + ' \\n')\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 단어장(vocabulary)을 만들고, 각 단어에 부여된 고유한 정수로 텍스트 시퀀스를 정수 시퀀스로 변환하는 정수 인코딩 과정을 거치겠습니다. 이때 영어와 프랑스어는 사용하는 언어가 다르므로 단어장을 별도로 만들어줍니다. 그리고 정상적으로 정수 시퀀스로 변환되었는지 3개의 행을 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[19, 3, 8], [10, 5, 8], [10, 5, 8]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_tokenizer = Tokenizer(char_level=True)   # 문자 단위로 Tokenizer를 생성합니다. \n",
    "eng_tokenizer.fit_on_texts(lines.eng)               # 50000개의 행을 가진 eng의 각 행에 토큰화를 수행\n",
    "input_text = eng_tokenizer.texts_to_sequences(lines.eng)    # 단어를 숫자값 인덱스로 변환하여 저장\n",
    "input_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[11, 1, 19, 4, 1, 33, 1, 12],\n",
       " [11, 1, 3, 4, 13, 7, 5, 1, 33, 1, 12],\n",
       " [11, 1, 3, 4, 13, 7, 5, 14, 1, 12]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fra_tokenizer = Tokenizer(char_level=True)   # 문자 단위로 Tokenizer를 생성합니다. \n",
    "fra_tokenizer.fit_on_texts(lines.fra)                 # 50000개의 행을 가진 fra의 각 행에 토큰화를 수행\n",
    "target_text = fra_tokenizer.texts_to_sequences(lines.fra)     # 단어를 숫자값 인덱스로 변환하여 저장\n",
    "target_text[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어장의 크기를 변수로 저장해줍니다. 0번 토큰을 고려하여 +1을 하고 저장해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어장의 크기 : 51\n",
      "프랑스어 단어장의 크기 : 73\n"
     ]
    }
   ],
   "source": [
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 영어 데이터와 프랑스어 데이터의 최대 길이를 각각 구해보겠습니다. 이는 패딩(< pad >)을 위함입니다. 모델에 입력될 영어, 프랑스어 시퀀스의 길이가 일정해야 하므로, 최대 길이로 맞추고 남는 시퀀스 뒷부분을 패딩으로 채우게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 시퀀스의 최대 길이 23\n",
      "프랑스어 시퀀스의 최대 길이 76\n"
     ]
    }
   ],
   "source": [
    "max_eng_seq_len = max([len(line) for line in input_text])\n",
    "max_fra_seq_len = max([len(line) for line in target_text])\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체적인 통계 정보를 한꺼번에 출력해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 50000\n",
      "영어 단어장의 크기 : 51\n",
      "프랑스어 단어장의 크기 : 73\n",
      "영어 시퀀스의 최대 길이 23\n",
      "프랑스어 시퀀스의 최대 길이 76\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플의 수 :',len(lines))\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인코더의 입력으로 사용되는 영어 시퀀스와 달리, 프랑스어 시퀀스는 2가지 버전으로 나누어 준비해야 합니다. 하나는 디코더의 출력과 비교해야 할 정답 데이터로 사용해야 할 원래 목적에 따른 것입니다. 그리고 다른 하나는 이전 스텝에서 언급했던 교사 강요(Teacher forcing)을 위해 디코더의 입력으로 사용하기 위한 것입니다.\n",
    "\n",
    "이때, 디코더의 입력으로 사용할 시퀀스는 < eos >토큰이 필요가 없고, 디코더의 출력과 비교할 시퀀스는 < sos >가 필요가 없기 때문입니다. 가령, 영어로 'I am a person'이라는 문장을 프랑스어 'Je suis une personne'로 번역하는 번역기를 만든다고 해봅시다. 훈련 과정에서 디코더는 '< sos > Je suis une personne'를 입력받아서 'Je suis une personne < eos >'를 예측하도록 훈련되므로, 이런 방식으로 생성된 두가지 버전의 시퀀스를 준비해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = input_text\n",
    "# 종료 토큰 제거\n",
    "decoder_input = [[ char for char in line if char != fra_tokenizer.word_index[eos_token] ] for line in target_text] \n",
    "# 시작 토큰 제거\n",
    "decoder_target = [[ char for char in line if char != fra_tokenizer.word_index[sos_token] ] for line in target_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "디코더의 입력과 출력을 각각 출력해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11, 1, 19, 4, 1, 33, 1], [11, 1, 3, 4, 13, 7, 5, 1, 33, 1], [11, 1, 3, 4, 13, 7, 5, 14, 1]]\n",
      "[[1, 19, 4, 1, 33, 1, 12], [1, 3, 4, 13, 7, 5, 1, 33, 1, 12], [1, 3, 4, 13, 7, 5, 14, 1, 12]]\n"
     ]
    }
   ],
   "source": [
    "print(decoder_input[:3])\n",
    "print(decoder_target[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "디코더의 입력의 경우에는 숫자 12(< eos > 토큰)가 제거되었고, 디코더의 출력의 경우에는 숫자 11(< sos > 토큰)이 제거되었습니다. 이제 패딩을 진행합니다. 패딩을 진행하면 모든 샘플들의 길이가 정해준 길이로 동일하게 변환됩니다. 여기서는 아까 저장해두었던 가장 긴 샘플의 길이인 max_eng_seq_len, max_fra_seq_len를 각각 사용하였습니다.\n",
    "\n",
    "이렇게 되면 영어 데이터의 모든 샘플들은 max_eng_seq_len의 길이를 가지고, 프랑스어의 모든 샘플들은 max_fra_seq_len의 길이가 되겠죠?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (50000, 23)\n",
      "프랑스어 입력데이터의 크기(shape) : (50000, 76)\n",
      "프랑스어 출력데이터의 크기(shape) : (50000, 76)\n"
     ]
    }
   ],
   "source": [
    "encoder_input = pad_sequences(encoder_input, maxlen = max_eng_seq_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen = max_fra_seq_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen = max_fra_seq_len, padding='post')\n",
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 샘플들의 길이가 동일하게 변환된 것을 알 수 있습니다. 모든 샘플들의 길이가 동일하게 변환되는 과정에서 정해준 길이보다 짧은 데이터들은 뒤에 0(< pad >)으로 채워집니다. 인코더의 샘플 하나만 출력해볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19  3  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 [19, 3, 8]이라는 3개의 단어만 있단 샘플이 뒤에 0이 채워지면서 max_eng_seq_len의 값인 23의 길이를 가지게 되었습니다. 이제 각 정수에 대해서 벡터화 방법으로 원-핫 인코딩을 선택합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (50000, 23, 51)\n",
      "프랑스어 입력데이터의 크기(shape) : (50000, 76, 73)\n",
      "프랑스어 출력데이터의 크기(shape) : (50000, 76, 73)\n"
     ]
    }
   ],
   "source": [
    "encoder_input = to_categorical(encoder_input)\n",
    "decoder_input = to_categorical(decoder_input)\n",
    "decoder_target = to_categorical(decoder_target)\n",
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원-핫 인코딩을 하고나서의 데이터의 크기는 (샘플의 수 × 샘플의 길이 × 단어장의 크기)가 됩니다. 원-핫 인코딩은 각 정수를 단어장의 크기를 가지는 원-핫 벡터로 인코딩하는 과정이기 때문입니다.\n",
    "\n",
    "마지막으로, 훈련과정의 validation을 위해 위에서 생성한 데이터 50000건 중 3000건만 검증데이터로 삼고, 나머지를 학습데이터로 삼겠습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (50000, 23, 51)\n",
      "프랑스어 입력데이터의 크기(shape) : (50000, 76, 73)\n",
      "프랑스어 출력데이터의 크기(shape) : (50000, 76, 73)\n",
      "영어 학습 데이터의 크기(shape) : (47000, 23, 51)\n",
      "프랑스어 학습 입력데이터의 크기(shape) : (47000, 76, 73)\n",
      "프랑스어 학습 출력데이터의 크기(shape) : (47000, 76, 73)\n",
      "영어 검증 데이터의 크기(shape) : (3000, 23, 51)\n",
      "프랑스어 검증 입력데이터의 크기(shape) : (3000, 76, 73)\n",
      "프랑스어 검증 출력데이터의 크기(shape) : (3000, 76, 73)\n"
     ]
    }
   ],
   "source": [
    "n_of_val = 3000\n",
    "\n",
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('영어 학습 데이터의 크기(shape) :',np.shape(encoder_input_train))\n",
    "print('프랑스어 학습 입력데이터의 크기(shape) :',np.shape(decoder_input_train))\n",
    "print('프랑스어 학습 출력데이터의 크기(shape) :',np.shape(decoder_target_train))\n",
    "\n",
    "print('영어 검증 데이터의 크기(shape) :',np.shape(encoder_input_test))\n",
    "print('프랑스어 검증 입력데이터의 크기(shape) :',np.shape(decoder_input_test))\n",
    "print('프랑스어 검증 출력데이터의 크기(shape) :',np.shape(decoder_target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 번역기 만들기 (2) 모델 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "print('⏳')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 인코더를 설계해볼까요? 인코더는 디코더보다 상대적으로 간단합니다. LSTM 셀을 설계하고나서 문장을 입력받으면 LSTM 셀이 마지막 time step의 hidden state와 cell state를 전달받아서 저장해줍니다. 앞서 인코더의 마지막 hidden state를 디코더의 첫번째 hidden state로 사용한다고 했었지요? 일반적인 기본 RNN의 경우에는 그것이 맞지만, 기본 RNN보다 좀 더 복잡한 LSTM의 경우에는 hidden state뿐만 아니라, cell sate라는 것이 존재합니다.\n",
    "\n",
    "그래서 인코더 LSTM 셀의 마지막 time step의 hidden state와 cell state를 디코더 LSTM의 첫번째 hidden state와 cell state로 전달해주어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 텐서 생성.\n",
    "encoder_inputs = Input(shape=(None, eng_vocab_size))\n",
    "# hidden size가 256인 인코더의 LSTM 셀 생성\n",
    "encoder_lstm = LSTM(units = 256, return_state = True)\n",
    "# 디코더로 전달할 hidden state, cell state를 리턴. encoder_outputs은 여기서는 불필요.\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "# hidden state와 cell state를 다음 time step으로 전달하기 위해서 별도 저장.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 코드를 한 줄, 한 줄 파악해볼게요.\n",
    "\n",
    "첫번째 줄 : 우선 LSTM의 입력 텐서를 정의해줍니다. 입력 문장을 저장하게 될 변수 텐서입니다.\n",
    "\n",
    "두번째 줄 : 256의 hidden_size를 가지는 LSTM 셀을 만들어줍니다. LSTM의 수용력(capacity)를 의미합니다. return_state = True를 해서 hidden state와 cell state를 리턴받을 수 있도록 합니다.\n",
    "\n",
    "세번째 줄 : 입력 텐서를 입력으로 마지막 time step의 hidden state와 cell state를 결과로 받습니다.\n",
    "\n",
    "네번째 줄 : 마지막 time step의 hidden state와 cell state를 encoder_states라는 하나의 변수에 저장해뒀습니다. 이를 디코더에 전달하면 되겠네요.\n",
    "\n",
    "이제 디코더를 설계해볼까요? 디코더도 인코더랑 몇 가지 세부 사항을 제외하고 거의 똑같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 텐서 생성.\n",
    "decoder_inputs = Input(shape=(None, fra_vocab_size))\n",
    "# hidden size가 256인 인코더의 LSTM 셀 생성\n",
    "decoder_lstm = LSTM(units = 256, return_sequences = True, return_state=True)\n",
    "# decoder_outputs는 모든 time step의 hidden state\n",
    "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state = encoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "세번째 줄을 보면 디코더의 인자로 initial_state가 추가되었는데요. LSTM 셀의 초기 상태를 정의해줄 수 있는 인자입니다. 여기서는 이전에 저장한 인코더의 마지막 time step의 hidden state와 cell state를 사용하였습니다. 디코더의 출력층을 설계해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "매 time step마다의 다중 클래스 분류 문제이므로 프랑스어 단어장으로부터 한 가지 문자만 선택하도록 합니다. Dense의 인자로 프랑스어 단어장의 크기를 기재하고, 활성화 함수로 소프트맥스 함수를 사용. 최종적으로 인코더와 디코더를 연결해서 하나의 모델로 만들어줍니다. Model의 Input과 Output의 정의를 유심히 살펴 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 51)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None, 73)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 256), (None, 315392      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  337920      input_2[0][0]                    \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 73)     18761       lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 672,073\n",
      "Trainable params: 672,073\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "368/368 [==============================] - 6s 16ms/step - loss: 0.9152 - val_loss: 0.8011\n",
      "Epoch 2/50\n",
      "368/368 [==============================] - 6s 15ms/step - loss: 0.5708 - val_loss: 0.6652\n",
      "Epoch 3/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.4725 - val_loss: 0.5699\n",
      "Epoch 4/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.4132 - val_loss: 0.5226\n",
      "Epoch 5/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.3751 - val_loss: 0.4824\n",
      "Epoch 6/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.3476 - val_loss: 0.4553\n",
      "Epoch 7/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.3271 - val_loss: 0.4305\n",
      "Epoch 8/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.3100 - val_loss: 0.4180\n",
      "Epoch 9/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.2962 - val_loss: 0.4081\n",
      "Epoch 10/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.2847 - val_loss: 0.4047\n",
      "Epoch 11/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.2749 - val_loss: 0.3922\n",
      "Epoch 12/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.2662 - val_loss: 0.3880\n",
      "Epoch 13/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.2584 - val_loss: 0.3823\n",
      "Epoch 14/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.2515 - val_loss: 0.3752\n",
      "Epoch 15/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.2451 - val_loss: 0.3748\n",
      "Epoch 16/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.2394 - val_loss: 0.3748\n",
      "Epoch 17/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.2340 - val_loss: 0.3683\n",
      "Epoch 18/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.2290 - val_loss: 0.3744\n",
      "Epoch 19/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.2243 - val_loss: 0.3675\n",
      "Epoch 20/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.2199 - val_loss: 0.3687\n",
      "Epoch 21/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.2158 - val_loss: 0.3644\n",
      "Epoch 22/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.2118 - val_loss: 0.3670\n",
      "Epoch 23/50\n",
      "368/368 [==============================] - 5s 15ms/step - loss: 0.2081 - val_loss: 0.3689\n",
      "Epoch 24/50\n",
      "368/368 [==============================] - 5s 15ms/step - loss: 0.2044 - val_loss: 0.3634\n",
      "Epoch 25/50\n",
      "368/368 [==============================] - 5s 15ms/step - loss: 0.2011 - val_loss: 0.3635\n",
      "Epoch 26/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.1978 - val_loss: 0.3685\n",
      "Epoch 27/50\n",
      "368/368 [==============================] - 5s 15ms/step - loss: 0.1947 - val_loss: 0.3653\n",
      "Epoch 28/50\n",
      "368/368 [==============================] - 5s 15ms/step - loss: 0.1917 - val_loss: 0.3680\n",
      "Epoch 29/50\n",
      "368/368 [==============================] - 5s 15ms/step - loss: 0.1888 - val_loss: 0.3705\n",
      "Epoch 30/50\n",
      "368/368 [==============================] - 5s 15ms/step - loss: 0.1860 - val_loss: 0.3668\n",
      "Epoch 31/50\n",
      "368/368 [==============================] - 5s 15ms/step - loss: 0.1833 - val_loss: 0.3697\n",
      "Epoch 32/50\n",
      "368/368 [==============================] - 5s 15ms/step - loss: 0.1807 - val_loss: 0.3686\n",
      "Epoch 33/50\n",
      "368/368 [==============================] - 5s 15ms/step - loss: 0.1783 - val_loss: 0.3753\n",
      "Epoch 34/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.1759 - val_loss: 0.3771\n",
      "Epoch 35/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.1735 - val_loss: 0.3786\n",
      "Epoch 36/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.1712 - val_loss: 0.3796\n",
      "Epoch 37/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.1690 - val_loss: 0.3796\n",
      "Epoch 38/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.1668 - val_loss: 0.3812\n",
      "Epoch 39/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.1648 - val_loss: 0.3827\n",
      "Epoch 40/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.1628 - val_loss: 0.3831\n",
      "Epoch 41/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.1608 - val_loss: 0.3881\n",
      "Epoch 42/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.1589 - val_loss: 0.3902\n",
      "Epoch 43/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.1569 - val_loss: 0.3914\n",
      "Epoch 44/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.1552 - val_loss: 0.3970\n",
      "Epoch 45/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.1535 - val_loss: 0.3951\n",
      "Epoch 46/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.1517 - val_loss: 0.3991\n",
      "Epoch 47/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.1501 - val_loss: 0.4011\n",
      "Epoch 48/50\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.1485 - val_loss: 0.3992\n",
      "Epoch 49/50\n",
      "368/368 [==============================] - 5s 15ms/step - loss: 0.1469 - val_loss: 0.4111\n",
      "Epoch 50/50\n",
      "368/368 [==============================] - 5s 15ms/step - loss: 0.1453 - val_loss: 0.4053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe5a144ac50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size=128, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 번역기 만들기 (3) 모델 테스트하기\n",
    "\n",
    "seq2seq는 훈련할 때와 테스트 단계의 동작이 다릅니다. 이를 위해서 테스트 단계의 디코더 모델은 설계를 다시 해줄 필요가 있습니다. 물론 이전에 학습된 디코더 모델의 레이어는 그대로 사용합니다. 왜 이렇게 번거로운 과정이 생기는 것일까요? Text Generator 모델을 만들어 보신 분이라면 알 수 있습니다. 훈련시에는 학습해야 할 타겟 문장을 디코더 모델의 입력, 출력 시퀀스로 넣어 주고, 디코더 모델이 타겟 문장을 한꺼번에 출력하게 할 수 있습니다. 그러나 테스트 단계에서는 그럴 수가 없습니다. 하나의 문장을 만들어 내기 위해 루프를 돌면서 단어를 하나씩 차례차례 예측해서, 예측한 단어가 다시 다음 단어를 예측할 때 사용되는 입력으로 재사용되는 과정이 진행되기 때문입니다.\n",
    "\n",
    "정리하면, 테스트 단계에서의 디코더의 동작 순서는 아래와 같습니다.\n",
    "\n",
    "1. 인코더에 입력 문장을 넣어 마지막 time step의 hidden, cell state를 얻는다.\n",
    "2. 토큰인 '\\t'를 디코더에 입력한다.\n",
    "3. 이전 time step의 출력층의 예측 결과를 현재 time step의 입력으로 한다.\n",
    "4. 3을 반복하다가 토큰인 '\\n'가 예측되면 이를 중단한다.\n",
    "\n",
    "이를 구현하기 위해서 훈련 과정에서와의 차이점은 이전 time step의 출력층의 예측 결과를 현재 time step의 입력으로 사용하는 단계를 추가하기 위해서 루프를 돌며 디코더의 LSTM 셀을 마치 수동 제어하는 느낌으로 설계해야 합니다. 코드가 좀 더 길어지게 되는데요.\n",
    "\n",
    "우선 인코더를 정의합니다. encoder_inputs와 encoder_states는 이미 정의한 것들을 재사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, 51)]        0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  [(None, 256), (None, 256) 315392    \n",
      "=================================================================\n",
      "Total params: 315,392\n",
      "Trainable params: 315,392\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 디코더를 설계합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전 time step의 hidden state를 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "# 이전 time step의 cell state를 저장하는 텐서\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "# 이전 time step의 hidden state와 cell state를 하나의 변수에 저장\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# decoder_states_inputs를 현재 time step의 초기 상태로 사용.\n",
    "# 구체적인 동작 자체는 def decode_sequence()에 구현.\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state = decoder_states_inputs)\n",
    "# 현재 time step의 hidden state와 cell state를 하나의 변수에 저장.\n",
    "decoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 과정에서의 디코더보다 코드가 좀 더 길어졌죠? 이전 time step의 출력 결과를 현재 time step의 입력으로 사용하기 위해서 디코더 LSTM 셀의 동작을 좀 더 세분화해서 구현했습니다. 동작 자체는 이후에 구현할 def decode_sequence()에서 좀 더 자세히 다루겠습니다.\n",
    "\n",
    "디코더의 출력층을 재설계해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None, 73)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  337920      input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 73)     18761       lstm_1[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 356,681\n",
      "Trainable params: 356,681\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어에서 정수로, 정수에서 단어로 바꾸는 사전(dictionary)을 준비해 둡니다. 테스트 결과를 해석하기 위해선 다시 사전이 필요하겠죠? 우리는 이전 스텝에서 문장을 숫자 인덱스로 바꾸는 Tokenizer를 만들면서 자동으로 만들어진 사전을 이미 가지고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng2idx = eng_tokenizer.word_index\n",
    "fra2idx = fra_tokenizer.word_index\n",
    "idx2eng = eng_tokenizer.index_word\n",
    "idx2fra = fra_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 예측 과정을 위한 함수 decode_sequence()를 구현합니다. decode_sequence()의 입력으로 들어가는 것은 번역하고자 하는 문장의 정수 시퀀스입니다. decode_sequence() 내부에는 인코더를 구현한 encoder_model이 있어서 이 모델에 번역하고자 하는 문장의 정수 시퀀스인 'input_seq'를 입력하면, encoder_model은 마지막 시점의 hidden state를 리턴합니다.\n",
    "\n",
    "states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "이 hidden state는 디코더의 첫번째 시점의 hidden state가 되고, 디코더는 이제 번역 문장을 완성하기 위한 예측 과정을 진행합니다. 디코더의 예측 과정에서는 이전 시점에서 예측한 단어를 디코더의 현재 시점의 입력으로 넣어주는 작업을 진행합니다. 그리고 이 작업은 종료를 의미하는 종료 토큰을 만나거나, 주어진 최대 길이를 넘을 때까지 반복합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1, 1, fra_vocab_size))\n",
    "    target_seq[0, 0, fra2idx['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 문자로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = idx2fra[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_fra_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1, 1, fra_vocab_size))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 구현한 함수를 임의의 인덱스의 번역하고자하는 문장 샘플을 입력하여,\n",
    "\n",
    "출력 결과를 테스트해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장: Run!\n",
      "정답 문장:  Cours ! \n",
      "번역기가 번역한 문장:  cours-tu ! \n",
      "-----------------------------------\n",
      "입력 문장: I left.\n",
      "정답 문장:  Je suis partie. \n",
      "번역기가 번역한 문장:  je suis parti. \n",
      "-----------------------------------\n",
      "입력 문장: Call us.\n",
      "정답 문장:  Appelez-nous ! \n",
      "번역기가 번역한 문장:  appelle ça ! \n",
      "-----------------------------------\n",
      "입력 문장: How nice!\n",
      "정답 문장:  Comme c'est gentil ! \n",
      "번역기가 번역한 문장:  comme c'est bizarre ! \n",
      "-----------------------------------\n",
      "입력 문장: Turn left.\n",
      "정답 문장:  Tourne à gauche. \n",
      "번역기가 번역한 문장:  tourne ! \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for seq_index in [3,50,100,300,1001]: # 입력 문장의 인덱스 (자유롭게 선택해 보세요)\n",
    "    input_seq = encoder_input[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장:', lines.eng[seq_index])\n",
    "    print('정답 문장:', lines.fra[seq_index][1:len(lines.fra[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
    "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1]) # '\\n'을 빼고 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일부 정답 문장과 다른 번역을 하는 경우도 있지만, 대체적으로 정답 문장과 거의 비슷한 번역을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로젝트 : 단어 Level로 번역기 업그레이드하기\n",
    "\n",
    "실습에서 구현한 번역기는 글자 단위(Character-level)에서 구현된 번역기였습니다. 하지만 실제 번역기의 경우에는 글자 단위가 아니라 단어 단위(Word-level)에서 구현되는 것이 좀 더 보편적입니다.\n",
    "\n",
    "동일한 데이터셋을 사용하면서 글자 단위와는 다른 전처리와 임베딩 층(Embedding layer)를 추가하여 단어 단위의 번역기를 완성시켜보겠습니다. 하지만, 단어 단위로 할 경우에는 단어의 개수가 글자 단위로 했을 경우와 비교하여 단어장의 크기(Vocabulary) 크기도 커지고, 학습 속도도 좀 더 느려집니다. 학습과 테스트 시의 원활한 진행을 위해서 데이터에서 상위 33,000개의 샘플만 사용해주세요.\n",
    "\n",
    "33000개 중 3000개는 테스트 데이터로 분리하여 모델을 학습한 후에 번역을 테스트 하는 용도로 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 178009\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140537</th>\n",
       "      <td>The problem is too difficult to solve.</td>\n",
       "      <td>Le problème est trop difficile à résoudre.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13656</th>\n",
       "      <td>Are you Catholic?</td>\n",
       "      <td>Es-tu catholique ?</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70386</th>\n",
       "      <td>I work out whenever I can.</td>\n",
       "      <td>Je m'exerce chaque fois que je peux.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97735</th>\n",
       "      <td>I don't walk anywhere anymore.</td>\n",
       "      <td>Je ne marche plus nulle part.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143921</th>\n",
       "      <td>Some believe Nessie lives in this lake.</td>\n",
       "      <td>Certains croient que Nessie vit dans ce lac.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            eng  \\\n",
       "140537   The problem is too difficult to solve.   \n",
       "13656                         Are you Catholic?   \n",
       "70386                I work out whenever I can.   \n",
       "97735            I don't walk anywhere anymore.   \n",
       "143921  Some believe Nessie lives in this lake.   \n",
       "\n",
       "                                                 fra  \\\n",
       "140537    Le problème est trop difficile à résoudre.   \n",
       "13656                             Es-tu catholique ?   \n",
       "70386           Je m'exerce chaque fois que je peux.   \n",
       "97735                  Je ne marche plus nulle part.   \n",
       "143921  Certains croient que Nessie vit dans ce lac.   \n",
       "\n",
       "                                                       cc  \n",
       "140537  CC-BY 2.0 (France) Attribution: tatoeba.org #4...  \n",
       "13656   CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "70386   CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "97735   CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n",
       "143921  CC-BY 2.0 (France) Attribution: tatoeba.org #5...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "file_path = os.getenv('HOME')+'/aiffel/translator_seq2seq/data/fra.txt'\n",
    "lines = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.sample(5) #샘플 5개 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27609</th>\n",
       "      <td>Why come to me now?</td>\n",
       "      <td>Pourquoi venir à moi maintenant ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>I paid.</td>\n",
       "      <td>J’ai payé.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17227</th>\n",
       "      <td>We're on our own.</td>\n",
       "      <td>Nous sommes seuls.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8480</th>\n",
       "      <td>I'm fascinated.</td>\n",
       "      <td>Je suis fasciné.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9944</th>\n",
       "      <td>You're my boss.</td>\n",
       "      <td>Vous êtes mon patron.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       eng                                fra\n",
       "27609  Why come to me now?  Pourquoi venir à moi maintenant ?\n",
       "53                 I paid.                         J’ai payé.\n",
       "17227    We're on our own.                 Nous sommes seuls.\n",
       "8480       I'm fascinated.                   Je suis fasciné.\n",
       "9944       You're my boss.              Vous êtes mon patron."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines[['eng', 'fra']][:33000] # 33,000개 샘플만 사용\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. 정제, 정규화, 전처리 (영어, 프랑스어 모두!)\n",
    "글자 단위가 아닌 단어 단위의 번역기를 하기 위해서는 글자 단위에서는 신경쓰지 않았던 몇 가지 추가적인 전처리가 필요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 구두점(Punctuation)을 단어와 분리해주세요.\n",
    "일반적으로 영어권 언어의 경우에는 띄어쓰기 단위로 단어를 분리합니다. 토큰화(Tokenization)이라고도 불리는 이 작업은 어디서부터 어디까지가 하나의 단어인지를 구분하는 작업인데요. 그런데 띄어쓰기를 해주기 전에 구두점을 분리하는 작업이 필요할 때가 있습니다.\n",
    "\n",
    "예를 들어서 'he is a good boy!'라는 문장이 있을 때, 이를 띄어쓰기 단위로 토큰화한다면\n",
    "\n",
    "['he', 'is', 'a', 'good', 'boy!']가 됩니다. 그런데 실제로 !는 boy와 붙어있는 한 단어가 아니므로\n",
    "\n",
    "좀 더 올바른 전처리는 ['he', 'is', 'a', 'good', 'boy', '!']가 맞습니다.\n",
    "\n",
    "!나 ? 또는 온점과 같은 특수문자들을 구두점(punctuation)이라고 부릅니다.\n",
    "\n",
    "이들을 토큰화하기 전에 단어와 미리 분리시켜주세요!\n",
    "\n",
    "분리 전 : he is a Good boy!\n",
    "\n",
    "분리 후 : he is a Good boy !\n",
    "\n",
    "\n",
    "### 2. 소문자로 바꿔주세요.\n",
    "기계가 보기에는 스펠링이 같더라도 대문자로 된 단어와 소문자로 된 단어는 서로 다른 단어입니다. 예를 들어 'Good'과 'good'은 기계가 보기에는 다른 단어입니다. 그래서 모든 문장에 대해서 전부 영어로 바꿔주는 작업을 하겠습니다.\n",
    "\n",
    "변환 전 : he is a Good boy !\n",
    "\n",
    "변환 후 : he is a good boy !\n",
    "\n",
    "\n",
    "### 3. 띄어쓰기 단위로 토큰를 수행하세요.\n",
    "띄어쓰기 단위로 토큰화를 수행해서 단어를 분리하는 작업을 해주세요. 기계는 이렇게 분리된 토큰들을 각각 하나의 단어로 인식할 수 있게 됩니다.\n",
    "\n",
    "토큰화 전 : 'he is a good boy !'\n",
    "\n",
    "토큰화 후 : ['he', 'is', 'a', 'good', 'boy', '!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23646</th>\n",
       "      <td>he is a bad person .</td>\n",
       "      <td>c est une mauvaise personne .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15088</th>\n",
       "      <td>i need new tires .</td>\n",
       "      <td>il me faut des pneus neufs .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32058</th>\n",
       "      <td>they know who he is .</td>\n",
       "      <td>elles savent qui c est .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4783</th>\n",
       "      <td>you may swim .</td>\n",
       "      <td>tu as la permission de nager .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24005</th>\n",
       "      <td>i am not a teacher .</td>\n",
       "      <td>je ne suis pas enseignant .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          eng                              fra\n",
       "23646   he is a bad person .    c est une mauvaise personne . \n",
       "15088     i need new tires .     il me faut des pneus neufs . \n",
       "32058  they know who he is .         elles savent qui c est . \n",
       "4783          you may swim .   tu as la permission de nager . \n",
       "24005   i am not a teacher .      je ne suis pas enseignant . "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29558</th>\n",
       "      <td>i do not understand .</td>\n",
       "      <td>je ne comprends pas .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29906</th>\n",
       "      <td>i like boston a lot .</td>\n",
       "      <td>j aime beaucoup boston .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32986</th>\n",
       "      <td>what time is it now ?</td>\n",
       "      <td>quelle heure est il pr sent ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20930</th>\n",
       "      <td>stop it right now !</td>\n",
       "      <td>arr tez imm diatement !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18624</th>\n",
       "      <td>he had no coat on .</td>\n",
       "      <td>il ne portait pas de manteau .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          eng                              fra\n",
       "29558  i do not understand .            je ne comprends pas . \n",
       "29906  i like boston a lot .         j aime beaucoup boston . \n",
       "32986  what time is it now ?    quelle heure est il pr sent ? \n",
       "20930    stop it right now !          arr tez imm diatement ! \n",
       "18624    he had no coat on .   il ne portait pas de manteau . "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re                  # 정규표현식을 위한 Regex 지원 모듈 (문장 데이터를 정돈하기 위해) \n",
    "\n",
    "def preprocess_sentence(sentence) :\n",
    "    \n",
    "    # 전처리 부분\n",
    "\n",
    "    # 구두점을 단어와 분리를 시켜본다\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)        # 패턴의 특수문자를 만나면 특수문자 양쪽에 공백을 추가\n",
    "    sentence = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sentence)       # 소문자, 대문자 알파벳, 구분자를 제외한 문자 공백으로 치환\n",
    "    sentence = re.sub(r\"\\s+\", r\" \", sentence)                 # 여러 공백문자들을 하나의 공백으로 치환\n",
    "    \n",
    "    sentence = sentence.lower()                               # 모두 소문자로 변환\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "lines.eng = lines.eng.apply(lambda x : preprocess_sentence(x))\n",
    "lines.fra = lines.fra.apply(lambda x : preprocess_sentence(x))\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. 디코더의 문장에 시작 토큰과 종료 토큰을 넣어주세요.\n",
    "\n",
    "글자 단위 번역기를 구현할 때와 마찬가지로 디코더의 입력 시퀀스 맨 앞에는 시작을 의미하는 토큰인 가 필요합니다. 그리고 교사 강요를 수행할 때, 디코더의 실제값이 되는 디코더의 레이블 시퀀스에는 종료를 의미하는 종료 토큰 가 필요합니다.\n",
    "\n",
    "예를 들어 번역 문장이 Courez!이었다고 한다면, Step 1을 거친 후에는 다음과 같은 결과를 얻습니다.\n",
    "\n",
    "Step 1을 수행한 후 : ['courez', '!']\n",
    "\n",
    "이 문장에 대해서 각각 디코더의 입력 시퀀스와 레이블 시퀀스를 만들면 다음과 같습니다.\n",
    "\n",
    "입력 시퀀스 : ['', 'courez', '!']\n",
    "\n",
    "레이블 시퀀스 : ['courez', '!', ']\n",
    "\n",
    "참고로 Step 2가 반드시 Step 1이 끝난 후에 이루어질 필요는 없습니다!\n",
    "\n",
    "Step 1을 수행하는 중간에 수행해도 상관없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 :  33000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>cheer up !</td>\n",
       "      <td>&lt;sos&gt; courage !  &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11001</th>\n",
       "      <td>i hate that guy .</td>\n",
       "      <td>&lt;sos&gt; je d teste ce type .  &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13452</th>\n",
       "      <td>you re charming .</td>\n",
       "      <td>&lt;sos&gt; vous tes charmants .  &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17100</th>\n",
       "      <td>we mean business .</td>\n",
       "      <td>&lt;sos&gt; ce que nous voulons c est faire des affa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7987</th>\n",
       "      <td>i got expelled .</td>\n",
       "      <td>&lt;sos&gt; j ai t expuls e .  &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       eng                                                fra\n",
       "258            cheer up !                              <sos> courage !  <eos>\n",
       "11001   i hate that guy .                   <sos> je d teste ce type .  <eos>\n",
       "13452   you re charming .                   <sos> vous tes charmants .  <eos>\n",
       "17100  we mean business .   <sos> ce que nous voulons c est faire des affa...\n",
       "7987     i got expelled .                      <sos> j ai t expuls e .  <eos>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 시작 토큰과 종료 토큰 추가\n",
    "sos_token = '<sos>'\n",
    "eos_token = '<eos>'\n",
    "lines.fra = lines.fra.apply(lambda x : sos_token + ' ' + x + ' ' + eos_token)\n",
    "print('전체 샘플의 수 : ', len(lines))\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. 케라스의 토크나이저로 텍스트를 숫자로 바꿔보세요.\n",
    "딥 러닝 모델은 각 단어를 텍스트가 아닌 숫자를 처리합니다. 케라스 토크나이저를 사용해서 각 단어를 고유한 정수로 바꿔보세요. 케라스 토크나이저의 사용법은\n",
    "\n",
    "아래의 링크에서 2. 케라스(Keras)의 텍스트 전처리 에 설명되어져 있습니다.\n",
    "\n",
    "위 링크의 가이드를 통해서 영어와 프랑스어에 대한 토크나이저를 각각 생성하고,\n",
    "\n",
    "tokenizer.texts_to_sequences()를 사용하여 모든 샘플에 대해서 정수 시퀀스로 변환해보세요.\n",
    "\n",
    "### 단어 단위 토큰화\n",
    "- Tokenizer의 인자 중 char_level은 default값으로 False이다.\n",
    "- 이 인자를 True로 사용한다면 글자 단위의 토큰화를 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[30, 1], [1132, 1], [1132, 1]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_tokenizer = Tokenizer(filters=\"\", lower=False)            # 토큰화 수행 : 문자 단위 X\n",
    "eng_tokenizer.fit_on_texts(lines.eng)   # 33000개의 데이터 각 행을 토큰화\n",
    "input_text = eng_tokenizer.texts_to_sequences(lines.eng)   # 단어를 숫자값 인덱스로 변환\n",
    "input_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 91, 12, 2], [1, 1068, 12, 2], [1, 1068, 3, 2]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fra_tokenizer = Tokenizer(filters=\"\", lower=False)\n",
    "fra_tokenizer.fit_on_texts(lines.fra)\n",
    "target_text = fra_tokenizer.texts_to_sequences(lines.fra)\n",
    "target_text[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어장의 사이즈를 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어장의 크기 :  4662\n",
      "프랑스어 단어장의 크기:  7326\n"
     ]
    }
   ],
   "source": [
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
    "print(\"영어 단어장의 크기 : \", eng_vocab_size)\n",
    "print(\"프랑스어 단어장의 크기: \", fra_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 디코더의 데이터 수정\n",
    "\n",
    "- 디코더의 입력에는 <eos> 토큰이 필요없음\n",
    "- 디코더의 출력과 비교할 시퀀스는 <sos>가 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = input_text\n",
    "\n",
    "# 종료 토큰 제거\n",
    "decoder_input = [[ char for char in line if char != fra_tokenizer.word_index[eos_token] ] for line in target_text]\n",
    "# 시작 토큰 제거\n",
    "decoder_target = [[ char for char in line if char != fra_tokenizer.word_index[sos_token] ] for line in target_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 91, 12], [1, 1068, 12], [1, 1068, 3]]\n",
      "[[91, 12, 2], [1068, 12, 2], [1068, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "print(decoder_input[:3])\n",
    "print(decoder_target[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 패딩추가를 위해서 최대 길이를 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 시퀀스의 최대 길이 8\n",
      "프랑스어 시퀀스의 최대 길이 17\n"
     ]
    }
   ],
   "source": [
    "max_eng_seq_len = max([len(line) for line in input_text])\n",
    "max_fra_seq_len = max([len(line) for line in target_text])\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 33000\n",
      "영어 단어장의 크기 : 4662\n",
      "프랑스어 단어장의 크기 : 7326\n",
      "영어 시퀀스의 최대 길이 :  8\n",
      "프랑스어 시퀀스의 최대 길이 :  17\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플의 수 :',len(lines))\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)\n",
    "print('영어 시퀀스의 최대 길이 : ', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이 : ', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 패딩 추가\n",
    "\n",
    "- max_eng_seq_len, max_fra_seq_len을 활용해서 해당 길이보다 짧다면 패딩을 채워준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (33000, 8)\n",
      "프랑스어 입력데이터의 크기(shape) : (33000, 17)\n",
      "프랑스어 출력데이터의 크기(shape) : (33000, 17)\n"
     ]
    }
   ],
   "source": [
    "encoder_input = pad_sequences(encoder_input, maxlen=max_eng_seq_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen=max_fra_seq_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen=max_fra_seq_len, padding='post')\n",
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_to_index = eng_tokenizer.word_index## Step 3. 케라스의 토크나이저로 텍스트를 숫자로 바꿔보세요.\n",
    "딥 러닝 모델은 각 단어를 텍스트가 아닌 숫자를 처리합니다. 케라스 토크나이저를 사용해서 각 단어를 고유한 정수로 바꿔보세요. 케라스 토크나이저의 사용법은\n",
    "\n",
    "아래의 링크에서 2. 케라스(Keras)의 텍스트 전처리 에 설명되어져 있습니다.\n",
    "\n",
    "위 링크의 가이드를 통해서 영어와 프랑스어에 대한 토크나이저를 각각 생성하고,\n",
    "\n",
    "tokenizer.texts_to_sequences()를 사용하여 모든 샘플에 대해서 정수 시퀀스로 변환해보세요.\n",
    "index_to_eng = eng_tokenizer.index_word\n",
    "\n",
    "fra_to_index = fra_tokenizer.word_index\n",
    "index_to_fra = fra_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 나누기\n",
    "- 데이터를 나누기 전에 먼저 한번 섞어준 후에 Training 3만개, Test 3천개로 나눈다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (33000, 8)\n",
      "프랑스어 입력데이터의 크기(shape) : (33000, 17)\n",
      "프랑스어 출력데이터의 크기(shape) : (33000, 17)\n"
     ]
    }
   ],
   "source": [
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10486 11682 12787 ... 28537 30209 26258]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (33000, 8)\n",
      "프랑스어 입력데이터의 크기(shape) : (33000, 17)\n",
      "프랑스어 출력데이터의 크기(shape) : (33000, 17)\n",
      "영어 학습 데이터의 크기(shape) : (30000, 8)\n",
      "프랑스어 학습 입력데이터의 크기(shape) : (30000, 17)\n",
      "프랑스어 학습 출력데이터의 크기(shape) : (30000, 17)\n",
      "영어 검증 데이터의 크기(shape) : (3000, 8)\n",
      "프랑스어 검증 입력데이터의 크기(shape) : (3000, 17)\n",
      "프랑스어 검증 출력데이터의 크기(shape) : (3000, 17)\n"
     ]
    }
   ],
   "source": [
    "n_of_val = 3000\n",
    "\n",
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('영어 학습 데이터의 크기(shape) :',np.shape(encoder_input_train))\n",
    "print('프랑스어 학습 입력데이터의 크기(shape) :',np.shape(decoder_input_train))\n",
    "print('프랑스어 학습 출력데이터의 크기(shape) :',np.shape(decoder_target_train))\n",
    "\n",
    "print('영어 검증 데이터의 크기(shape) :',np.shape(encoder_input_test))\n",
    "print('프랑스어 검증 입력데이터의 크기(shape) :',np.shape(decoder_input_test))\n",
    "print('프랑스어 검증 출력데이터의 크기(shape) :',np.shape(decoder_target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. 임베딩 층(Embedding layer) 사용하기\n",
    "이번에는 입력이 되는 각 단어를 임베딩 층을 사용하여 벡터화하겠습니다.\n",
    "\n",
    "임베딩 층을 사용하는 방법과 그 설명에 대해서는 아래의 링크의\n",
    "\n",
    "케라스 임베딩 층(Keras Embedding layer)를 참고하세요.\n",
    "\n",
    "실제 번역기 구현을 위해서 사용할 수 있는 인코더 코드의 예시는 다음과 같습니다.\n",
    "\n",
    "이를 통해서 인코더와 디코더의 임베딩 층을 각각 구현해보세요.\n",
    "\n",
    "주의할 점은 인코더와 디코더의 임베딩 층은 서로 다른 임베딩 층을 사용해야 하지만,\n",
    "\n",
    "디코더의 훈련 과정과 테스트 과정(예측 과정)에서의 임베딩 층은 동일해야 합니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM의 출력 차원\n",
    "latent_dim = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인코더 설계\n",
    "- Masking은 패딩 토큰의 숫자 0의 경우에는 연산을 제외하는 역할을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb = Embedding(eng_vocab_size, latent_dim)(encoder_inputs) # 임베딩층\n",
    "enc_masking = Masking(mask_value=0.0)(enc_emb)  # 패딩 0은 연산에서 제외\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)  # 상태값 리턴\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking)  # 은닉 상태와 셀 상태를 리턴\n",
    "encoder_states = [state_h, state_c]  # 인코더의 은닉 상태외 셀 상태를 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 디코더 설계\n",
    "- optimizer : rmsprop\n",
    "- loss : sparse_categorical_crossentropy\n",
    "- mterics : acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더\n",
    "decoder_inputs = Input(shape=(None, ))\n",
    "dec_emb_layer = Embedding(fra_vocab_size, latent_dim)  # 임베딩 층\n",
    "dec_emb = dec_emb_layer(decoder_inputs)  # 패딩 0은 언제나 연산에서 제외\n",
    "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
    "\n",
    "# 상태값 리턴을 위해 return_state는 True, 모든 시점에 대해서 단어를 예측하기 위해 return_sequence는 True\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "\n",
    "# 인코더의 은닉 상태를 초기 은닉 상태 (initial_state)로 사용\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_masking, initial_state=encoder_states)\n",
    "\n",
    "# 모든 시점에 결과에 대해 소프트맥스 함수를 사용한 출력층을 통해 단어 예측\n",
    "decoder_dense = Dense(fra_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. 모델 구현하기\n",
    "글자 단위 번역기에서 구현한 모델을 참고로 단어 단위 번역기의 모델을 완성시켜보세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 32)     149184      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 32)     234432      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, None, 32)     0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 32)     0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 32), (None,  8320        masking[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 32), ( 8320        masking_1[0][0]                  \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 7326)   241758      lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 642,014\n",
      "Trainable params: 642,014\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.6316 - acc: 0.8910 - val_loss: 0.9045 - val_acc: 0.8511\n",
      "Epoch 2/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.6300 - acc: 0.8915 - val_loss: 0.9058 - val_acc: 0.8509\n",
      "Epoch 3/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.6286 - acc: 0.8919 - val_loss: 0.9029 - val_acc: 0.8505\n",
      "Epoch 4/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.6270 - acc: 0.8921 - val_loss: 0.9067 - val_acc: 0.8508\n",
      "Epoch 5/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.6256 - acc: 0.8922 - val_loss: 0.9050 - val_acc: 0.8511\n",
      "Epoch 6/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.6243 - acc: 0.8926 - val_loss: 0.9021 - val_acc: 0.8513\n",
      "Epoch 7/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.6229 - acc: 0.8928 - val_loss: 0.9058 - val_acc: 0.8510\n",
      "Epoch 8/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.6216 - acc: 0.8930 - val_loss: 0.9036 - val_acc: 0.8523\n",
      "Epoch 9/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.6199 - acc: 0.8932 - val_loss: 0.9079 - val_acc: 0.8514\n",
      "Epoch 10/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.6188 - acc: 0.8935 - val_loss: 0.9058 - val_acc: 0.8520\n",
      "Epoch 11/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.6174 - acc: 0.8939 - val_loss: 0.9017 - val_acc: 0.8525\n",
      "Epoch 12/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.6161 - acc: 0.8938 - val_loss: 0.9075 - val_acc: 0.8518\n",
      "Epoch 13/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.6151 - acc: 0.8939 - val_loss: 0.9023 - val_acc: 0.8524\n",
      "Epoch 14/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.6136 - acc: 0.8943 - val_loss: 0.9076 - val_acc: 0.8523\n",
      "Epoch 15/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.6126 - acc: 0.8944 - val_loss: 0.9082 - val_acc: 0.8518\n",
      "Epoch 16/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.6113 - acc: 0.8947 - val_loss: 0.9093 - val_acc: 0.8520\n",
      "Epoch 17/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.6104 - acc: 0.8949 - val_loss: 0.9060 - val_acc: 0.8521\n",
      "Epoch 18/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.6091 - acc: 0.8952 - val_loss: 0.9070 - val_acc: 0.8523\n",
      "Epoch 19/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.6081 - acc: 0.8953 - val_loss: 0.9090 - val_acc: 0.8521\n",
      "Epoch 20/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.6071 - acc: 0.8954 - val_loss: 0.9037 - val_acc: 0.8532\n",
      "Epoch 21/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.6059 - acc: 0.8957 - val_loss: 0.9061 - val_acc: 0.8526\n",
      "Epoch 22/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.6048 - acc: 0.8957 - val_loss: 0.9098 - val_acc: 0.8511\n",
      "Epoch 23/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.6038 - acc: 0.8961 - val_loss: 0.9076 - val_acc: 0.8527\n",
      "Epoch 24/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.6028 - acc: 0.8962 - val_loss: 0.9070 - val_acc: 0.8520\n",
      "Epoch 25/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.6016 - acc: 0.8965 - val_loss: 0.9123 - val_acc: 0.8521\n",
      "Epoch 26/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.6007 - acc: 0.8967 - val_loss: 0.9093 - val_acc: 0.8515\n",
      "Epoch 27/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5996 - acc: 0.8968 - val_loss: 0.9069 - val_acc: 0.8528\n",
      "Epoch 28/100\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.5986 - acc: 0.8968 - val_loss: 0.9072 - val_acc: 0.8520\n",
      "Epoch 29/100\n",
      "235/235 [==============================] - 7s 32ms/step - loss: 0.5978 - acc: 0.8972 - val_loss: 0.9133 - val_acc: 0.8512\n",
      "Epoch 30/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5969 - acc: 0.8971 - val_loss: 0.9127 - val_acc: 0.8516\n",
      "Epoch 31/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5959 - acc: 0.8974 - val_loss: 0.9049 - val_acc: 0.8527\n",
      "Epoch 32/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5950 - acc: 0.8974 - val_loss: 0.9142 - val_acc: 0.8511\n",
      "Epoch 33/100\n",
      "235/235 [==============================] - 7s 32ms/step - loss: 0.5940 - acc: 0.8977 - val_loss: 0.9108 - val_acc: 0.8519\n",
      "Epoch 34/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5931 - acc: 0.8978 - val_loss: 0.9106 - val_acc: 0.8518\n",
      "Epoch 35/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5921 - acc: 0.8980 - val_loss: 0.9091 - val_acc: 0.8516\n",
      "Epoch 36/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5913 - acc: 0.8982 - val_loss: 0.9082 - val_acc: 0.8523\n",
      "Epoch 37/100\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.5902 - acc: 0.8983 - val_loss: 0.9087 - val_acc: 0.8518\n",
      "Epoch 38/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5892 - acc: 0.8985 - val_loss: 0.9073 - val_acc: 0.8517\n",
      "Epoch 39/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5882 - acc: 0.8987 - val_loss: 0.9147 - val_acc: 0.8507\n",
      "Epoch 40/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5874 - acc: 0.8987 - val_loss: 0.9077 - val_acc: 0.8518\n",
      "Epoch 41/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5867 - acc: 0.8987 - val_loss: 0.9070 - val_acc: 0.8523\n",
      "Epoch 42/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5856 - acc: 0.8991 - val_loss: 0.9077 - val_acc: 0.8516\n",
      "Epoch 43/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5850 - acc: 0.8992 - val_loss: 0.9084 - val_acc: 0.8524\n",
      "Epoch 44/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5840 - acc: 0.8994 - val_loss: 0.9076 - val_acc: 0.8524\n",
      "Epoch 45/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5834 - acc: 0.8991 - val_loss: 0.9088 - val_acc: 0.8522\n",
      "Epoch 46/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5824 - acc: 0.8996 - val_loss: 0.9219 - val_acc: 0.8502\n",
      "Epoch 47/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5817 - acc: 0.8997 - val_loss: 0.9119 - val_acc: 0.8525\n",
      "Epoch 48/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5810 - acc: 0.8996 - val_loss: 0.9101 - val_acc: 0.8517\n",
      "Epoch 49/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5802 - acc: 0.8998 - val_loss: 0.9070 - val_acc: 0.8522\n",
      "Epoch 50/100\n",
      "235/235 [==============================] - 7s 32ms/step - loss: 0.5793 - acc: 0.8999 - val_loss: 0.9178 - val_acc: 0.8512\n",
      "Epoch 51/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5786 - acc: 0.9001 - val_loss: 0.9103 - val_acc: 0.8526\n",
      "Epoch 52/100\n",
      "235/235 [==============================] - 7s 32ms/step - loss: 0.5778 - acc: 0.9002 - val_loss: 0.9136 - val_acc: 0.8518\n",
      "Epoch 53/100\n",
      "235/235 [==============================] - 7s 32ms/step - loss: 0.5770 - acc: 0.9004 - val_loss: 0.9140 - val_acc: 0.8519\n",
      "Epoch 54/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5763 - acc: 0.9004 - val_loss: 0.9152 - val_acc: 0.8522\n",
      "Epoch 55/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5756 - acc: 0.9006 - val_loss: 0.9109 - val_acc: 0.8530\n",
      "Epoch 56/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5746 - acc: 0.9006 - val_loss: 0.9225 - val_acc: 0.8508\n",
      "Epoch 57/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5741 - acc: 0.9008 - val_loss: 0.9127 - val_acc: 0.8520\n",
      "Epoch 58/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5733 - acc: 0.9010 - val_loss: 0.9105 - val_acc: 0.8527\n",
      "Epoch 59/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5726 - acc: 0.9010 - val_loss: 0.9135 - val_acc: 0.8524\n",
      "Epoch 60/100\n",
      "235/235 [==============================] - 7s 32ms/step - loss: 0.5720 - acc: 0.9013 - val_loss: 0.9140 - val_acc: 0.8518\n",
      "Epoch 61/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5712 - acc: 0.9011 - val_loss: 0.9119 - val_acc: 0.8522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5705 - acc: 0.9014 - val_loss: 0.9129 - val_acc: 0.8531\n",
      "Epoch 63/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5699 - acc: 0.9016 - val_loss: 0.9139 - val_acc: 0.8521\n",
      "Epoch 64/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5692 - acc: 0.9015 - val_loss: 0.9105 - val_acc: 0.8523\n",
      "Epoch 65/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5684 - acc: 0.9018 - val_loss: 0.9131 - val_acc: 0.8527\n",
      "Epoch 66/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5676 - acc: 0.9019 - val_loss: 0.9129 - val_acc: 0.8525\n",
      "Epoch 67/100\n",
      "235/235 [==============================] - 7s 30ms/step - loss: 0.5672 - acc: 0.9019 - val_loss: 0.9100 - val_acc: 0.8530\n",
      "Epoch 68/100\n",
      "235/235 [==============================] - 7s 30ms/step - loss: 0.5666 - acc: 0.9020 - val_loss: 0.9151 - val_acc: 0.8524\n",
      "Epoch 69/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5660 - acc: 0.9023 - val_loss: 0.9140 - val_acc: 0.8527\n",
      "Epoch 70/100\n",
      "235/235 [==============================] - 7s 30ms/step - loss: 0.5653 - acc: 0.9023 - val_loss: 0.9137 - val_acc: 0.8523\n",
      "Epoch 71/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5645 - acc: 0.9024 - val_loss: 0.9202 - val_acc: 0.8521\n",
      "Epoch 72/100\n",
      "235/235 [==============================] - 7s 32ms/step - loss: 0.5641 - acc: 0.9024 - val_loss: 0.9176 - val_acc: 0.8517\n",
      "Epoch 73/100\n",
      "235/235 [==============================] - 7s 32ms/step - loss: 0.5634 - acc: 0.9026 - val_loss: 0.9160 - val_acc: 0.8527\n",
      "Epoch 74/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5630 - acc: 0.9027 - val_loss: 0.9150 - val_acc: 0.8521\n",
      "Epoch 75/100\n",
      "235/235 [==============================] - 7s 32ms/step - loss: 0.5621 - acc: 0.9028 - val_loss: 0.9165 - val_acc: 0.8518\n",
      "Epoch 76/100\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.5613 - acc: 0.9028 - val_loss: 0.9202 - val_acc: 0.8517\n",
      "Epoch 77/100\n",
      "235/235 [==============================] - 7s 32ms/step - loss: 0.5608 - acc: 0.9029 - val_loss: 0.9191 - val_acc: 0.8520\n",
      "Epoch 78/100\n",
      "235/235 [==============================] - 7s 32ms/step - loss: 0.5600 - acc: 0.9030 - val_loss: 0.9207 - val_acc: 0.8511\n",
      "Epoch 79/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5596 - acc: 0.9031 - val_loss: 0.9233 - val_acc: 0.8506\n",
      "Epoch 80/100\n",
      "235/235 [==============================] - 7s 32ms/step - loss: 0.5590 - acc: 0.9031 - val_loss: 0.9163 - val_acc: 0.8519\n",
      "Epoch 81/100\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.5584 - acc: 0.9033 - val_loss: 0.9175 - val_acc: 0.8519\n",
      "Epoch 82/100\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.5580 - acc: 0.9034 - val_loss: 0.9163 - val_acc: 0.8522\n",
      "Epoch 83/100\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.5574 - acc: 0.9036 - val_loss: 0.9194 - val_acc: 0.8520\n",
      "Epoch 84/100\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.5568 - acc: 0.9038 - val_loss: 0.9182 - val_acc: 0.8518\n",
      "Epoch 85/100\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.5562 - acc: 0.9037 - val_loss: 0.9172 - val_acc: 0.8519\n",
      "Epoch 86/100\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.5555 - acc: 0.9037 - val_loss: 0.9178 - val_acc: 0.8518\n",
      "Epoch 87/100\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.5551 - acc: 0.9039 - val_loss: 0.9195 - val_acc: 0.8519\n",
      "Epoch 88/100\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.5546 - acc: 0.9040 - val_loss: 0.9187 - val_acc: 0.8520\n",
      "Epoch 89/100\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.5541 - acc: 0.9041 - val_loss: 0.9169 - val_acc: 0.8521\n",
      "Epoch 90/100\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.5535 - acc: 0.9041 - val_loss: 0.9244 - val_acc: 0.8509\n",
      "Epoch 91/100\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.5531 - acc: 0.9042 - val_loss: 0.9193 - val_acc: 0.8518\n",
      "Epoch 92/100\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.5523 - acc: 0.9043 - val_loss: 0.9224 - val_acc: 0.8511\n",
      "Epoch 93/100\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.5521 - acc: 0.9042 - val_loss: 0.9207 - val_acc: 0.8514\n",
      "Epoch 94/100\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.5515 - acc: 0.9045 - val_loss: 0.9218 - val_acc: 0.8513\n",
      "Epoch 95/100\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.5510 - acc: 0.9043 - val_loss: 0.9210 - val_acc: 0.8517\n",
      "Epoch 96/100\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.5503 - acc: 0.9046 - val_loss: 0.9178 - val_acc: 0.8523\n",
      "Epoch 97/100\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.5498 - acc: 0.9044 - val_loss: 0.9185 - val_acc: 0.8525\n",
      "Epoch 98/100\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.5492 - acc: 0.9047 - val_loss: 0.9213 - val_acc: 0.8526\n",
      "Epoch 99/100\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.5486 - acc: 0.9050 - val_loss: 0.9195 - val_acc: 0.8515\n",
      "Epoch 100/100\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.5481 - acc: 0.9049 - val_loss: 0.9187 - val_acc: 0.8527\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size = 128, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들 \n",
    "\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# 빨간 실선으로 표시\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "# 파란 실선으로 표시\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xUVfr48c9DDZAAUoxAkKCiCEuPoAgYRARdy6K4wKosoLJWLF/buuvq6vpbddl19bs2VKy4rP1rwUqxskhVOoaiFClSTEJNeX5/PHeSSZgkE8gkkHner9e8MnPrOXcm57nnnHvPFVXFOeecK65GVSfAOefcockDhHPOuYg8QDjnnIvIA4RzzrmIPEA455yLyAOEc865iDxAuKiJyPsi8tuKXrYqicgaETkjBttVETkueP+EiNwZzbIHsJ+LReSjA02nc6URvw+iehOR7LCP9YG9QF7w+XeqOqnyU3XoEJE1wOWq+kkFb1eBdqqaUVHLikgqsBqoraq5FZFO50pTq6oT4GJLVRND70srDEWklhc67lDhv8dDgzcxxSkRSReRdSJym4hsBJ4VkSNE5F0R2SIi24P3KWHrzBCRy4P3o0TkCxEZHyy7WkTOOsBl24rIZyKSJSKfiMijIvJSCemOJo33isiXwfY+EpFmYfMvFZHvRWSriPyhlONzsohsFJGaYdOGiMi3wfueIjJTRHaIyI8i8i8RqVPCtp4Tkb+Efb4lWGeDiIwptuwvRWS+iGSKyFoRuTts9mfB3x0iki0ip4SObdj6vUVktoj8HPztHe2xKedxbiIizwZ52C4ib4XNO19EFgR5WCkig4PpRZrzROTu0PcsIqlBU9tlIvIDMC2Y/mrwPfwc/EY6hq1fT0T+HnyfPwe/sXoi8p6IXFcsP9+KyK8i5dWVzANEfDsKaAK0AcZiv4dng89HA7uBf5Wyfi9gOdAMeBB4RkTkAJZ9GfgaaArcDVxayj6jSeNvgNHAkUAd4GYAEekAPB5sv2WwvxQiUNX/AjuB04tt9+XgfR5wY5CfU4ABwNWlpJsgDYOD9AwE2gHF+z92AiOBxsAvgavCCrZ+wd/GqpqoqjOLbbsJ8B7wSJC3fwDviUjTYnnY79hEUNZxfhFrsuwYbOuhIA09gReAW4I89APWlHQ8IjgNOBEYFHx+HztORwLzgPAm0fFAD6A39ju+FcgHngcuCS0kIl2AVsCUcqTDAaiqv+Lkhf2jnhG8Twf2AQmlLN8V2B72eQbWRAUwCsgIm1cfUOCo8iyLFT65QP2w+S8BL0WZp0hp/GPY56uBD4L3fwImh81rEByDM0rY9l+AicH7JKzwblPCsjcAb4Z9VuC44P1zwF+C9xOB+8OWOz582Qjb/SfwUPA+NVi2Vtj8UcAXwftLga+LrT8TGFXWsSnPcQZaYAXxERGWezKU3tJ+f8Hnu0Pfc1jejiklDY2DZRphAWw30CXCcnWBbVi/Dlggeayy/9+qw8trEPFti6ruCX0Qkfoi8mRQZc/EmjQahzezFLMx9EZVdwVvE8u5bEtgW9g0gLUlJTjKNG4Me78rLE0tw7etqjuBrSXtC6stXCAidYELgHmq+n2QjuODZpeNQTr+H1abKEuRNADfF8tfLxGZHjTt/AxcGeV2Q9v+vti077Gz55CSjk0RZRzn1th3tj3Cqq2BlVGmN5KCYyMiNUXk/qCZKpPCmkiz4JUQaV+quhd4BbhERGoAI7AajysnDxDxrfglbP8DnAD0UtWGFDZplNRsVBF+BJqISP2waa1LWf5g0vhj+LaDfTYtaWFVXYIVsGdRtHkJrKlqGXaW2hC440DSgNWgwr0MvA20VtVGwBNh2y3rksMNWJNQuKOB9VGkq7jSjvNa7DtrHGG9tcCxJWxzJ1Z7DDkqwjLhefwNcD7WDNcIq2WE0vATsKeUfT0PXIw1/e3SYs1xLjoeIFy4JKzaviNoz74r1jsMzsjnAHeLSB0ROQU4N0ZpfA04R0T6BB3K91D2/8DLwDisgHy1WDoygWwRaQ9cFWUaXgFGiUiHIEAVT38Sdna+J2jP/03YvC1Y084xJWx7CnC8iPxGRGqJyDCgA/BulGkrno6Ix1lVf8T6Bh4LOrNri0gogDwDjBaRASJSQ0RaBccHYAEwPFg+DRgaRRr2YrW8+lgtLZSGfKy57h8i0jKobZwS1PYIAkI+8He89nDAPEC4cP8E6mFnZ/8FPqik/V6MdfRuxdr9/4MVDJEccBpVdTFwDVbo/whsB9aVsdq/sf6aaar6U9j0m7HCOwt4KkhzNGl4P8jDNCAj+BvuauAeEcnC+kxeCVt3F3Af8KXY1VMnF9v2VuAc7Ox/K9Zpe06xdEerrON8KZCD1aI2Y30wqOrXWCf4Q8DPwKcU1mruxM74twN/pmiNLJIXsBrcemBJkI5wNwMLgdlYn8MDFC3TXgA6YX1a7gD4jXLukCMi/wGWqWrMazCu+hKRkcBYVe1T1Wk5XHkNwlU5ETlJRI4NmiQGY+3Ob5W1nnMlCZrvrgYmVHVaDmceINyh4CjsEsxs7Br+q1R1fpWmyB22RGQQ1l+zibKbsVwpvInJOedcRF6DcM45F1G1GqyvWbNmmpqaGvXyO3fupEGDBrFL0CEoHvMM8ZnveMwzxGe+DybPc+fO/UlVm0eaV60CRGpqKnPmzIl6+RkzZpCenh67BB2C4jHPEJ/5jsc8Q3zm+2DyLCLF774v4E1MzjnnIvIA4ZxzLiIPEM455yLyAOGccy4iDxDOOeci8gDhnHMuIg8QzjnnIqpW90E451y1l5MDb78N69ZBt27QtWvMduUBwjnnDgc//ADPPgsTJsCGDUVmpR1zDGRkgFTswx89QDjnXGVShWXL4PPPISkJTjgBjj0Wli+Hjz6CadOgRg1o397mrV0L778PixbZ+oMHw5NPQo8eMH8+zJ3L9kWLSKzg4AAeIJxz7sDk5MDPPxd+3rvXmn2+/x7WrIEVK6zQX7MGGjaE5GT7O3v2fjWAAiLWZFS7Nrz4ImRm2vu+fWH8ePjVryyYhLRoAWefzcoZM0p9kPuB8gDhnItfmZmQlQVNm0JCQtF5eXnwzTd2pr94MWzdCj/9ZK9Nm+xzaY480moAp58O2dm2zvLl0KcPDBwI6emwZ49N++47SE2FAQOgeTBunips3AiJiVbTqAIeIJxz8SM725pqpk2DDz6Ar76yQACFBXGdOnbWvnmzBRCwwr55cwsk7dvDaafZtCZNrDkIoFYtSEmBo4+GNm2gUaPo0vSLX0SeLmI1hCrkAcI5V/38/DPMnWtn5ytXWgfu4sX2PvSQtO7d4bbboHVrqw1s3WoBISfHXo0bW9NO375W8MchDxDOucNHTo4V8itWwPr18OOP1nSzd6/VBPbu5aRZs+yKn5B69eCYY+yS0JEjoXNn6NULjjqq6vJxmPAA4Zyrert329n+kiWwahXs2GG1gMzMwn6CrVstOOTkFK4nYk0/CQlQsybUqsXulBQajB0LJ50EHTtaM00Nvyf4QHiAcM7Fnirs22edsZ9+aq+lSwsL/x07Cpt+AOrXtyt+wl8dOthVPCeeaP0AKSnWD1CraDG2KA4fGBQrHiCccwcuLw+++MLu7F29GrZvt8I+Kwt27bLX7t0WHMK1bm19AI0aWeHfrJkV/B07wnHHQd26VZMfV4QHCOdcZHv3Wlv/ihV29c++fTZt+/bCSz2nTYMtW6xAb9fOOnZTUqzQr1/fXgkJha+WLe0KoHI8O95VHQ8QzsWr3Fzr6G3Rwi7tBOsHePFFeP11Cwz5+ZHXDZ31DxgAF1xgd/dW0bX6LnY8QDhXHe3ZQ53iN3Kp2l28771nzUKzZsHOndaB26aN3QewcKF9HjAALrrI2v1POMGagurWtVejRnafgKv2PEA4V5388AM8/jg89RS9t261ppzTTrMbut54w4aBqFEDunSB0aOtzX/DBrtPYPNm+Nvf4De/saYgF/c8QDh3OAkNzTBrlg0B8fnn1hdQr5619//4oy13/vlkHHUUx23aBO++a5eMDhwId98N558PRxxRpdlwh4eYBggRGQw8DNQEnlbV+4vNPwKYCBwL7AHGqOqiaNZ1rtrKyrIAMHOm9RHs2GEdw6tW2SvUL5CcbHf5tm1rVwrt3m39CZdfDm3asG7GDI5LT7fl9+61IOJcOcQsQIhITeBRYCCwDpgtIm+r6pKwxe4AFqjqEBFpHyw/IMp1nTt85ebCggVWA5g5024C27nTzvRDncOhm8AaN7ZXly7W/NOhg90V3K5ddOP/16jhwcEdkFjWIHoCGaq6CkBEJgPnA+GFfAfgrwCqukxEUkUkGTgminWdO7Tl5tq4/9OmwdSpVivYvbvwjD50R3BqKrRqVXiJ6EUXwamnwsknRz/gm3MxEMsA0QpYG/Z5HdCr2DLfABcAX4hIT6ANkBLlugCIyFhgLEBycjIzZsyIOoHZ2dnlWr46iMc8QwXlOy+PhE2bqJ2VRa3MTGrk5JCTlERuo0Yo0GD1ahJXraLB6tXU/+EH6q1fT43cXAB2t2zJjm7dyGvQAK1Rg/zatdl57LHs6NSJfaHhnYubP/+gkuvfdfyIVZ5jGSAi1X212Of7gYdFZAGwEJgP5Ea5rk1UnQBMAEhLS9Py3GI/Iw5vyY/HPEM58719uzXLhJ+9T5sG48bZWEGlqVHDmn66dYPhw605qF8/6qWmUtmNPP5dx49Y5TmWAWIdFHnIUQpQ5DFKqpoJjAYQEQFWB6/6Za3r3EFTtTuC16yxYSJmzYLp061voEYN6N0bzjrLPr/yinUGP/64NQc1aWI3l23bZv0Hubl2yWiHDt7e76qNWAaI2UA7EWkLrAeGA78JX0BEGgO7VHUfcDnwmapmikiZ6zp3wBYvhueeg5desid2hdSta0Hhz3+2PoIpU+COO2yIiD//GW65xQt/F1diFiBUNVdErgU+xC5Vnaiqi0XkymD+E8CJwAsikod1QF9W2rqxSqurJrKz4bPP4OOP4csv7Qy/eXNo0oQOq1fDvffaM4NXrLARQH/5S+jf3zqJU1Ph+OOLBoC//MUCSM2ahY+BdC6OxPQ+CFWdAkwpNu2JsPczgXbRrutcEdnZdl/ARx/B++/bJaM5OXbGf/LJdgnoypXw9dckhoaT6NABrrrKLhc98siy9+EPlXFxzO+kdoe+HTvgv/+FOXPsMZILF9qZ/c6dhcv84hdwww1w5pn2UPhiD6D/Og47Lp07WB4g3KElNMT0okU2sNynn9rlnqGHyRx/vD1HICXFzu5btYJ+/ez5As65CuUBwlW+nTvtyp/mza3Nf9MmG176lVes7yC4d4C6deGUU+Cuu2xIiR49/MYx5yqRBwgXO1lZdufwEUfY8NBz58KTT8LLLxc2DzVoUHh38Yknwv/8D3Ttak1Gxx9f+JwC51yl8wDhKlZ+vjULPf201Qr27rXpDRpYUKhXz24gO/lkuwdhyxarFQwdakHBOXfI8ADhymf3busfWLAAvv0WvvnG7ivYs8cuB1W1q4saN7ZRRU880W4m27bNnjV88cU2zzl3yPMA4cq2ciVMmmQ1gsWL7UH1YE8g69zZBpdLSrK+g7w86NkTLrzQbypz7jDnAcIVlZMDM2bYmEPLl9ulpbNn2z0F/frB739vfQRdu9rQEzVqVHWKnXMx4gHCmb17bfiJ+++3sYnAmoI6dIAHH4QRI+zSUudc3PAAEWdq7toFkyfDa6/BvHl2Q1mDBvZc4g0boFcv+Mc/7HkEzZtH90Aa51y15AGiuvr5Z2semjXLmoo2boSNGzl16VJrRjrqKEhPt36D7Gy74eyaa+CMMzwoOOcADxDVx/btdnnp9On2WrSo8O7j1q2hZUto25b17dvT+rrrbNRS7z9wzpXCA8ThKi/P7jr+8EMbvXTuXLsHoV49ax666CJrLjrpJLtRLbByxgxa9+lThQl3zh0uPEAcTn76ya4oeucdeOMNG6KiZk276ezOO2HAALvEtG7dqk6pc64a8ABxKMvPh08+geeft9rC99/b9Pr17VkGF15oTzxr2LBq0+mcq5Y8QFSljRvh1VetgG/TxvoJtmyxy0yXLrWb09asscdbDhwI115rA9b16mVBwjnnYsgDRFXYsMHuLXjySRuioiSnnw5//SsMGeLNRs65SucBorJ8/z289x68+y5MnWqdzCNH2nOOa9WCH36A9evt3oO2ba1G4UNVOOeqkAeIWMnJsfsQ3nnHgsLChTb9uOOsqeiaa+CYYwqXbxfxyavOOVdlPEBUBFXIyLBnIs+aZXcof/st7NtnVxn17Qvjx8O559ozDpxz7jDgAeJgrF9vfQmTJ8PmzTatcWPrSL7+ersHYeBAH97aOXdY8gARLVXYscPuPdi0yR6P+fTTdinqBRfYPQh9+8IJJ/gdys65asEDRGmWLYMpU6zp6Isv7Ea1kNq1YfRouP1261R2zrlqxgNEJF98YU1H77xjn485xm5M69IFkpPhyCOhY0do0aJq0+mcczHkASLcnDlw88026F3TpnD33XDZZf4cBOdcXPIAAdbZfMcd8MILVjt4+GELDA0aVHXKnHOuyniA2LHDnpq2Zw/cdpsFCh/byDnniOnlNiIyWESWi0iGiNweYX4jEXlHRL4RkcUiMjps3vUisiiYfkPMEtm4MTz0kI19dP/9Hhyccy4QsxqEiNQEHgUGAuuA2SLytqouCVvsGmCJqp4rIs2B5SIyCTgeuALoCewDPhCR91T1u5gkdsyYmGzWOecOZ7GsQfQEMlR1laruAyYD5xdbRoEkEREgEdgG5AInAv9V1V2qmgt8CgyJYVqdc84VIxp6LGVFb1hkKDBYVS8PPl8K9FLVa8OWSQLeBtoDScAwVX1PRE4E/g84BdgNTAXmqOp1EfYzFhgLkJyc3GPy5MlRpzE7O5vExMQDzOHhKR7zDPGZ73jMM8Rnvg8mz/3795+rqmmR5sWyk1oiTCsejQYBC4DTgWOBj0Xkc1VdKiIPAB8D2cA3WM1i/w2qTgAmAKSlpWl6enrUCZwxYwblWb46iMc8Q3zmOx7zDPGZ71jlOZZNTOuA1mGfU4ANxZYZDbyhJgNYjdUmUNVnVLW7qvbDmp5i0//gnHMuolgGiNlAOxFpKyJ1gOFYc1K4H4ABACKSDJwArAo+Hxn8PRq4APh3DNPqnHOumJg1MalqrohcC3wI1AQmqupiEbkymP8EcC/wnIgsxJqkblPV0IBHr4tIUyAHuEZVt8cqrc455/YX0xvlVHUKMKXYtCfC3m8Azixh3b6xTJtzzrnS+bjUzjnnIvIA4ZxzLiIPEM455yLyAOGccy4iDxDOOeci8gDhnHMuIg8QzjnnIvIA4ZxzLiIPEM455yLyAOGccy4iDxDOOeci8gDhnHMuIg8QzjnnIvIA4ZxzLiIPEM455yLyAOGccy4iDxDOOeci8gDhnHMuIg8QzjnnIiozQIjIOSLigcQ55+JMNAX/cOA7EXlQRE6MdYKcc84dGsoMEKp6CdANWAk8KyIzRWSsiCTFPHXOOeeqTFRNR6qaCbwOTAZaAEOAeSJyXQzT5pxzrgrVKmsBETkXGAMcC7wI9FTVzSJSH1gK/G9sk+icOxAiwurVq9mzZ09VJ6VSNWrUiKVLl1Z1MipVNHlOSEggJSWF2rVrR73dMgMEcBHwkKp+Fj5RVXeJyJio9+Scq1QNGjQgKSmJ1NRURKSqk1NpsrKySEqKrxbwsvKsqmzdupV169bRtm3bqLcbTRPTXcDXoQ8iUk9EUoOdTo16T865SlWzZk2aNm0aV8HBRSYiNG3atNy1yWgCxKtAftjnvGCac+4Q58HBhRzIbyGaAFFLVfeFPgTv60SZoMEislxEMkTk9gjzG4nIOyLyjYgsFpHRYfNuDKYtEpF/i0hCNPt0zlW9rVu30rVrV7p27cpRRx1Fq1atCj7v27ev1HXnzJnDuHHjytxH7969Kyq5rgTR9EFsEZHzVPVtABE5H/iprJVEpCbwKDAQWAfMFpG3VXVJ2GLXAEtU9VwRaQ4sF5FJQHNgHNBBVXeLyCvY/RjPlSNvzrkq0rRpUxYsWADA3XffTWJiIjfffHPB/NzcXGrVilz8pKWlkZaWVuY+vvrqq4pJbCXKy8ujZs2aVZ2MqEVTg7gSuENEfhCRtcBtwO+iWK8nkKGqq4Jax2Tg/GLLKJAkVvdJBLYBucG8WkA9EakF1Ac2RLFP59whatSoUdx0003079+f2267ja+//prevXvTrVs3evfuzfLlywGYMWMG55xzDmDBZcyYMaSnp3PMMcfwyCOPFGwvMTGxYPn09HSGDh1K+/btueyyy1BVAKZMmUL79u3p06cP48aNK9huuDVr1tC3b1+6d+9O9+7diwSeBx98kE6dOtGlSxduv90aQTIyMjjjjDPo0qUL3bt3Z+XKlUXSDHDttdfy3HPPAZCamso999xDnz59ePXVV3nqqac46aST6NKlCxdeeCG7du0CYNOmTQwZMoQuXbrQpUsXvvrqK+68804efvjhgu3+4Q9/KHIMYq3MGoSqrgROFpFEQFQ1K8pttwLWhn1eB/Qqtsy/gLexwj8JGKaq+cB6ERkP/ADsBj5S1Y8i7URExgJjAZKTk5kxY0aUyYPs7OxyLV8dxGOeIT7z3bBhQ7Ky7N+17m23UWPhwgrdfn6nTux94IEyl9u7dy+1a9cmJyeHJUuW8Oabb1KzZk0yMzN57733qFWrFtOnT+fWW2/lpZdeYteuXeTm5pKVlcXevXtZvHgx7733HtnZ2XTv3p1LLrmk4FLNrKwsdu3axfz585k1axYtWrRg4MCBfPzxx3Tr1o2xY8fy/vvvk5qayujRowu2G65evXq88cYbJCQkkJGRwWWXXcann37KRx99xOuvv84nn3xC/fr12bZtG1lZWQwfPpybbrqJc889lz179pCfn18kzQD79u1jz549ZGVloaqICO+//z5gzW/Dhw8H4J577uHRRx/lyiuv5Oqrr6ZXr1688MIL5OXlkZ2dzbBhw7jkkksYM2YM+fn5vPzyy0yfPn2/POTl5e03LZI9e/aU6/8gmiYmROSXQEcgIdTRoar3lLVahGla7PMgYAFwOnafxcci8jlQE6tttAV2AK+KyCWq+tJ+G1SdAEwASEtL0/T09GiyBBSeecSTeMwzxGe+58+fX3jpY506UNFNG3XqUCeKy0nr1q1L3bp1qV27NiNGjKBx48YA7NixgzFjxvDdd98hIuTk5JCUlET9+vWpVasWSUlJ1K1bl/POO49mzZrRrFkzkpOT2bVrFykpKQAFy/fs2ZP27dsD0LlzZzZv3sz69es59thj6dSpEwAjR45kwoQJ+10Omp+fz7XXXsuCBQuoWbMmK1asICkpia+++orLL7+c5OTkgn1lZWWxceNGfvOb3xRMA4qk2Q5NHRISEkhKSkJEGDlyZMG8efPmcemll7Jjxw6ys7MZNGgQSUlJfPbZZ7z88svUrVsXgMaNG5OSkkLz5s3JyMhg06ZN9OjRg9TU1P2OcbSX9iYkJNCtW7cylwuJ5ka5J7Amnv7A08BQwi57LcU6oHXY5xT2byYaDdyvVh/MEJHVQHugDbBaVbcEaXgD6A3sFyCcc1H45z+rOgWA3ZsRcuedd9K/f3/efPNN1qxZU2IADxWYYJfu5ubmlrpMjRo1yM3NLWhmKstDDz1EcnIy33zzDfn5+SQk2PUwoTP/cCVts1atWuTnF17sWfxy0vB8jxo1irfeeosuXbrw3HPPlXlGf/nll/Pcc8+xceNGxoyp3FvPoumD6K2qI4Htqvpn4BSKFvwlmQ20E5G2IlIH62R+u9gyPwADAEQkGTgBWBVMP1lE6gf9EwOwu7adc9XEzz//TKtWrQAK2usrUvv27Vm1ahVr1qwB4D//+U+J6WjRogU1atTgxRdfJC8vD4AzzzyTiRMnFvQRbNu2jYYNG5KSksJbb70FWPPZrl27aNOmDUuWLGHv3r38/PPPTJ1a8i1iWVlZtGjRgpycHCZNmlQwfcCAATz++OOANRllZmYCMGTIED744ANmz57NoEGDDu6glFM0ASIUCneJSEsgB2v6KZWq5gLXAh9ihfsrqrpYRK4UkSuDxe4FeovIQmAqcJuq/qSqs4DXgHnAwiCdE8qRL+fcIe7WW2/l97//PaeeempBoVyR6tWrx2OPPcbgwYPp06cPycnJNGrUaL/lrr76ap5//nlOPvlkVqxYUXC2P3jwYM477zzS0tLo2rUr48ePB+DFF1/kkUceoXPnzvTu3ZuNGzfSunVrfv3rX9O5c2cuvvjiUptx7r33Xnr16sXAgQMLmsUAHn74YaZPn06nTp3o0aMHixcvBqy5qn///vz617+u/CugVLXUF3An0Bi4ENgI/AjcU9Z6VfHq0aOHlsf06dPLtXx1EI95Vo3PfM+bN6+qk1AlMjMzC95nZWWpqmp+fr5eddVV+o9//KOqknXA8vLytEuXLrpixYoSlwnPc2mWLFmy3zRgjpZQppZagwgeFDRVVXeo6utY30B7Vf1TTKOWc85VgKeeeoquXbvSsWNHfv75Z373u2iu0D90LFmyhOOOO44BAwbQrl27St9/qZ3UqpovIn/H+h1Q1b3A3spImHPOHawbb7yRG2+8saqTccA6dOjAqlWrqmz/0fRBfCQiF4oP6uKcc3ElmvsgbgIaALkisge7v0FVtWFMU+acc65KRXMndXwNrO6ccw6I7ka5fpGma7EHCDnnnKteoumDuCXsdSfwDnB3DNPknDvMpaen8+GHHxaZ9s9//pOrr7661HXmzJkDwNlnn82OHTv2W+buu+8uuB+hJO+++y5LlhQOGv2nP/2JTz75pDzJd4FompjODf8sIq2BB2OWIufcYW/EiBFMnjy5yJ2/kydP5m9/+1tU60+ZMuWA9/3uu+9Su3ZtOnToANiAeIebQ2VY8GhqEMWtA35R0QlxzlUfQ4cO5d1332XvXrsqfs2aNWzYsIE+ffpw1VVXkZaWRseOHbnrrrsirp+amspPP9ljZ+677z5OOOEEzjjjjIIhwYGIw2Z/9dVXTJkyhVtuuYWuXbuycuVKRo0axWuvvQbA1KlT6datG506dSIvM1kAABzySURBVGLMmDEF6UtNTeWuu+6ie/fudOrUiWXLlu2XpkN5WPB77703JsOCR9MH8b8UjsJaA+gKfHPQe3bOVZobboDg+T0VpmvXkscAbNq0KT179uSDDz7g/PPPZ/LkyQwbNgwR4b777qNJkybk5eUxYMAAvv32Wzp37hxxO3PnzmXy5MnMnz+f3NxcunfvTo8ePQC44IILuOKKKwD44x//yDPPPMN1113H2WefzZAhQxg6dGiRbe3Zs4dRo0YxdepUjj/+eEaOHMnjjz/ODTfcAECzZs2YN28ejz32GOPHj+fpp58usv6RRx7Jxx9/TEJCAt999x0jRoxgzpw5vP/++7z11lvMmjWrYFhwgIsvvpjbb7+dIUOGFAwLvnbtWkqTkJDAF198Adiw4JHyN27cOE477TTefPPNgmHBGzZsyMiRI7n++uvJz89n8uTJfP11NGOqli6aGsQcYG7wmomNl3TJQe/ZOVethZqZwJqXRowYAcArr7xC9+7d6datG4sXLy7SX1Dc559/zpAhQ6hfvz4NGzbkvPPOK5i3aNEi+vbtS6dOnZg0aVLB2EUlWb58OW3btuX4448H4Le//S2ffVZ4rc0FF1wAQI8ePQoG+AuXk5PDFVdcQadOnbjooosK0v3JJ58wevRo6tevD0CTJk3Iyspi/fr1DBkyBLCCPzS/NMOGDSszf9OmTeOqq64CbHTbRo0a0aZNG5o2bcr8+fP56KOP6NatG02bNi1zf2WJ5j6I14A9qpoH9ihREamvqrsOeu/OuUpRFaN9/+pXv+Kmm25i3rx57N69m+7du7N69WrGjx/P7NmzOeKIIxg1atR+Q2MXV9I9uuUdNlvLGP47NGR4SUOKx+Ow4NHUIKYC9cI+1wP8kgDnXKkSExNJT09nzJgxBbWHzMxMGjRoQKNGjdi0aVPBU9ZK0q9fP9588012795NVlYW77zzTsG8kobNTkxMjPh0tfbt27NmzRoyMjIAG5X1tNNOizo/8TgseDQBIkFVs0Mfgvdl15Wcc3FvxIgRfPPNNwWP2OzSpQvdunWjY8eOjBkzhlNPPbXU9bt3786wYcPo2rUrF154IX379i2YV9Kw2UOHDuVvf/sb3bp1Y+XKlQXTExISePbZZ7nooovo1KkTNWrU4MorryRacTkseEnDvIZewJdA97DPPYCZZa1XFS8f7rts8Zhn1fjMtw/3HT8yMzOjGha8Qof7DtyAPRP68+B50f/BHgTknHPuELBs2bKYDAsezY1ys0WkPfY4UAGWqWpOhaXAOefcQQk9XrWilVmDEJFrgAaqukhVFwKJIlLy/fLOOeeqhWiamK5Q1YJBUVR1O3BF7JLknKsoWsalnS5+HMhvIZoAUSP8YUEiUhOoU+49OecqVV5eHlu3bvUg4VBVtm7dWnDvRrSiuVHuQ+AVEXkCG3LjSqD0i5edc1Vu586dZGVlsWXLlqpOSqXas2dPuQvCw100eU5ISCAlJaVc240mQNwGjAWuwjqp5wMtyrUX51ylU1Xatm1b1cmodDNmzCj1/oLqKFZ5LrOJSVXzgf8Cq4A0YACwtMJT4pxz7pBSYg1CRI4HhgMjgK3Y/Q+oav/KSZpzzrmqVFoT0zLgc+BcVc0AEJEbKyVVzjnnqlxpTUwXAhuB6SLylIgMwPognHPOxYESA4Sqvqmqw4D2wAzgRiBZRB4XkTMrKX3OOeeqSDSd1DtVdZKqngOkAAuA26PZuIgMFpHlIpIhIvutIyKNROQdEflGRBaLyOhg+gkisiDslSkiN5Qzb8455w5CNJe5FlDVbcCTwatUwQ11jwIDsedYzxaRt1U1/PFR1wBLVPVcEWkOLBeRSaq6HHu0aWg764E3y5NW55xzByeaO6kPVE8gQ1VXqeo+YDJwfrFlFEgK7tROBLYBxR/lNABYqarfxzCtzjnniollgGgFhD+he10wLdy/gBOBDcBC4Prgvotww4F/xyqRzjnnIpNYjdMiIhcBg1T18uDzpUBPVb0ubJmhwKnATcCxwMdAF1XNDObXwYJHR1XdVMJ+xmJ3epOcnNwj9JD0aGRnZ5OYmHgAuTt8xWOeIT7zHY95hvjM98HkuX///nNVNS3SvHL1QZTTOqB12OcUrLAPNxq4P3iqUYaIrMaumvo6mH8WMK+k4ACgqhOACQBpaWmanp4edQJnzJhBeZavDuIxzxCf+Y7HPEN85jtWeY5lE9NsoJ2ItA1qAsOBt4st8wPWx4CIJGMPJQp/6sUIvHnJOeeqRMxqEKqaKyLXYqPB1gQmqupiEbkymP8EcC/wnIgsxG7Cu01VfwIQkfrYFVC/i1UanXPOlSyWTUyo6hRgSrFpT4S93wBEvOlOVXcBTWOZPueccyWLZROTc865w5gHCOeccxF5gHDOOReRBwjnnHMReYBwzjkXkQcI55xzEXmAcM45F5EHCOeccxF5gHDOOReRBwjnnHMReYBwzjkXkQcI55xzEXmAcM45F5EHCOeccxF5gHDOOReRBwjnnHMReYBwzjkXkQcI55xzEXmAcM45F5EHCOeccxF5gHDOOReRBwjnnHMReYBwzjkXkQcI55xzEXmAcM45F5EHCOeccxF5gHDOORdRTAOEiAwWkeUikiEit0eY30hE3hGRb0RksYiMDpvXWEReE5FlIrJURE6JZVqdc84VFbMAISI1gUeBs4AOwAgR6VBssWuAJaraBUgH/i4idYJ5DwMfqGp7oAuwNFZpdc45t79Y1iB6AhmqukpV9wGTgfOLLaNAkogIkAhsA3JFpCHQD3gGQFX3qeqOGKbVOedcMbEMEK2AtWGf1wXTwv0LOBHYACwErlfVfOAYYAvwrIjMF5GnRaRBDNPqnHOuGFHV2GxY5CJgkKpeHny+FOipqteFLTMUOBW4CTgW+BhrTjoe+C9wqqrOEpGHgUxVvTPCfsYCYwGSk5N7TJ48Oeo0Zmdnk5iYeIA5PDzFY54hPvMdj3mG+Mz3weS5f//+c1U1LdK8WgeVqtKtA1qHfU7BagrhRgP3q0WpDBFZDbQHfgDWqeqsYLnXgP06uQFUdQIwASAtLU3T09OjTuCMGTMoz/LVQTzmGeIz3/GYZ4jPfMcqz7FsYpoNtBORtkHH83Dg7WLL/AAMABCRZOAEYJWqbgTWisgJwXIDgCUxTKtzzrliYlaDUNVcEbkW+BCoCUxU1cUicmUw/wngXuA5EVkICHCbqv4UbOI6YFIQXFZhtQ3nnHOVJJZNTKjqFGBKsWlPhL3fAJxZwroLgIjtYs4552LP76R2zjkXkQcI55xzEXmAcM45F5EHCOeccxF5gHDOOReRBwjnnHMReYBwzjkXkQcI55xzEXmAcM45F5EHCOeccxF5gHDOOReRBwjnnHMReYBwzjkXkQcI55xzEXmAcM45F5EHCOeccxF5gHDOOReRBwjnnHMReYCII59/DhMnprJrV1WnxFWV7Gz7HTgXDQ8QcWL1ajjvPHjxxVR69YJlyypu26oVty1nli+HE0+Ehx6quG3u2QNnnw39+sHEieVf/5NP4JRT4M9/hn37Ki5d7uDk50NeXmy27QGiilXG2fzu3XDhhfb+lluWsXEjpKXB5Mn7L7tyJVxyCSxaFN22N2yAtm3h6qshN7fs5VXhssvsdThThZyc8i3/9dfR/SMvWAB9+1oQ//vfS15n71645Ra44AKYNAmyskreZn4+jBxptYcTT7Tva86cyMu9/759P/fdBzNmwJo1cPHFMHAgZGTA3XdDz56WzjVr4IEHLHBceqn9fqI5FjffbNtYsaLs5eNdZibMnw+vvQbffbf//L//HW69tQvZ2THYuapWm1ePHj20PKZPn16u5csjM1P1o49U8/Mjz1+3TvXSS1VFVG+4QXXfvsJ5mzap/v73qrffrvroo6rvvGPbi8bWrarvvqv6xhuqP/5o08aMUQXbzvTp03XdOtVTT7V9z51bdP3zz7dl69VTff750veVn6961lmqtWrZOmedVXY6H37YlgXVL7+MLk/hduywvIUfr2iEvuslS1Szs/ef/+9/q958c+Hr739XnTlTde/eyNv7y19UmzZV/frr6Pb/+OOW51/+svRj9OWXqo0aqbZurfr//p+t88EH+y+3YYPqKafY/KOOKvzOxoxR3bataJ5V7TcGquPHq27Zotqmje1j82ab/+OP9ls74QRbLimp8HsC1Tp1VP/0J9Xdu1Xfeks1OVm1Ro3C+d272/5r1VK96irVBQts2Uj+8Y/CbTZqpPree9Edw2hF+r/OylLNyanY/cTKxx+r3nqr6qBBhd9t6NWwoerSpYXLzpxpx7xfv80lljVlAeZoCWVqlRfqFfk6lALEhRfa0b3nnqLT9+61wqV+ffsHGTTIluvbV3X9etUJE1SPOEK1Zk3V2rULfxhHHqn62GOFP/Jt21Rff131r39Vvf561WHDVE88seiPCawQANU//rFonnfsUG3e3PYb+mHNnGnLjhunetpp9v6SS1QfeMAKhz/8QTUjozAvTz1lyzzyiOqTT1qau3WzwiuSuXMtz2edZfk544zyHdOFC1XbtbN9du6sOnt29Os+/vgcPessW7d9ewsUqqp5eao33mjTExLse6lXr/D4JSRYwAiXk6PaooXNb9RI9b//tenZ2ap33GGF5cqVhctv3mzf6XHH2THq3Fn1hx8K5+/apfryy6qDB1uh266d6vffq+7Zo9qkiX234WbNsv03aKD66quWh88/V73ySissWrWyk5Np06brp5+qDh1qab3++sLveu5cy1vnzvYK5TctTXXSJPudhk42/vrXooWSqs277Tabt2qVTduwQfXqqwtPGGrUsDxffnnh8X7rLTsxufBCW69rV/v8xz+W/LtRVc3NVV29usyvWVULf+Pbt6u+8ELhSUzjxqojRlj+1q8v+eQtkl27VFesUP3kE9WXXlJ94gk7iXjhhfJtpzQ7dqiOHGnHrnZtOza//a39/732mur06fY/266d/f9v366ammrB/p13Pj/g/XqAKEGsAsTbb9uRPe44+/vPf9r0pUutAAXVCy4oLEQmTbKCKRQQ+vWzf6i8PPun+fhjmwZ2hnfyyUXP3pKSbF9nn616332qM2ZYYT9+vOqQIaqXXWb/YMXz/OSTtv6rr9qPPD3dCu7Q2dYdd9g/b2g/NWpYOh95xNKemKjav7+lU1V1yhQrtI49VnXNmqLHJDPT0tiqlepPP1nawAo2Vdv/HXeopqSoduyo2qePFYwPPWRn6aFjdNRR9o/ZsqWl57rrVF95RfXTT/ffp6qdxYaCdZMmdmZ25JGW9pdeKpw3blzhMVK14/7aa6rnnmvzly8vnPf++zbtoYdUjznGzurGj1c9+ujCoNKhg/3Dq6qOHm0F1OLFqh9+aMs3b26FcUpK4fd+9NF2DEJn9aqWv7p1C2sFGzZYPtq2Vf322/3zO3u2BUBQbdFil4IFpz/8ofB7CnnhBTum6elW0M+fXzGF3fffW43sT3+y45uQYOk5+2zb30knqe7cacvu3Kl68cU2X8R+Tw8/bLWKb7+1msitt9r3HTrmJcnMtP21arVTExMLf7dt2liQHz3avvvQ9GbNVAcMsHX691ft0sUK5UGDrGD+7W/td1j8LL746+GHi6ZjwwZL89q10R+zqVPt+69ZU/XOO+3kIJLPP7ffy5lnWuCvVcv+1w+mLPMAUYJYBIjMTDtr/8Uv7KzjggvsKF92mZ2ZNm1qZ1HFffut/QNNnBj5nzQ/39br3l21Vy/75/vyy8J/tGiF5zk3184eU1NV/+//tKA2UDw/2dlWuKxda2e5YIEgKWn/s7qZM+2s+uijC2sbc+aonn66FeiffWbTdu60ZorTT7e8jRtn2x00yI5Zerr9Y4f/I556auFZ5vbtqmPH7v/PWjz9oe2OGrWqoGln7VoLsqFCqbRCZ+NGq/VcfXXhtOHDrdDds8e2FToR6NTJ8jdtmv3jDh5sn8EKjJBFiyyfgwdbIXT77bZO8QJcVXXePFv/sccKm/QSEvY/ow+3a5cViN26bdOJE8v/G6lomzer3nWX/fbbtCls+gy3ZIn9pkM1xPBXzZqq55yjBTXAxx+PvJ+xY+37TE/fpNdfb0Hvq6+K/j/l5VmN75FH7H8yLc1q3n36qJ53nu3npJPsf7hVKzsxGz1a9d57rcl1+nTVZcusBrJjh51A1KljwVXVfpehGlmLFvbbL83y5XYSB6rHH19YGy3N008XHpsHHrBpHiBiGCDWrCl69liW/Hyrbj75pBUWv/qVFbC5uVaNF7EfpqoVIqFmpDPPLL0aXRmK/5CmTrW01a1rgaKkM5eQ/HwLYi1b2hloJHPnWmHQsqUFgFAtp/g/dqgtOhR0brxx/+C4bp3qf/5jzVmR+h22brXg+tFH1r5fo4ad4ata80iodlA833v3WvPf22+Xnl9V1VGj7Mx32zYrFBISigaMjRutFhPexj1hghb0C6SkWK3sQHXpYoVWqMZX/Iy1JLFsQj0Qu3dH7v8Jl59v3/lXX9n3PnGi9cmp2ncWqtFNnFh0vVCt7pZbKjffW7ZYIGjf3n6L/frZGf6jj9pJUv361nz4yivWfJSSYq0AZ5xhgaFWLavN3ntv+QL5PfeoXnFF4UmFB4gYBYi8PDvjTUy0L/d//qfkjsdFi6ytNHTGGDpLCFV/W7e2Auqqq4qut3t3yWeIlS3SDynUMV1Wp3R5LFxoNYSWLVUffLCwuSXcrl2F1febbz745o2sLCtMGza0wNesmX3evfvg/oEWLLA0PvhgYcEfTed0qGP4tdcOeNeqajWcUNPVgAHR/44OtQBREXbvthMtEWt+27rVAnerVtasd7Df9YGYOtXS07y5fU8vv2zTf/xRtWfPwrIi1J80dKhNP/po6zfauPHg0+ABIkYBYt8+KxivvdaaburUsaMybJi1s2/bpvq//2sFTagd/owz7Gx4+XIr1HJy7MqaAQOsaSlSYXioiPRD2rjRCr7y1KKikZ1d9tVG06ZZh19FdfR9/70FptDZe6hz9GALjf797QTg5JOtSSKa9OblqX733UHtVlWtiaZWLTuRCe/cLkt1DBCqdqZ99dX2v9ikiWrv3tYMFWrOqYp8//73WqS/MWTXLtVnnrG+g1heRXVYBghgMLAcyABujzC/EfAO8A2wGBgdNm8NsBBYUFoGwl8V0QeRmWltoaGrjEIdbN27W7tlRUT7qlRdC41wM2daZ+SzzxZOO9h8h/poQPX++w9qUwdk4kS7gqY8qvt3/e23hU2Yd91VOL0q8h1qdq4qsQoQtWJwawUAIlITeBQYCKwDZovI26q6JGyxa4AlqnquiDQHlovIJFUN3afZX1V/ilUaI0lKsjtFf/c7uwEoPx9Gj4bu3SszFe5gnHwybNwIIhW3zXPOgWOPtTvSL7mk4rYbrdGjK3+fh7pOnezu7mXLoH37qk2LCLRrV7VpiIWYBQigJ5ChqqsARGQycD4QHiAUSBIRARKBbUAU9+PGXsuW8PDDVZ0Kd6AqMjgA1KgBTzwBixdDq1YVu2134ETsznAXG2I1jBhsWGQoMFhVLw8+Xwr0UtVrw5ZJAt4G2gNJwDBVfS+YtxrYjgWRJ1V1Qgn7GQuMBUhOTu4xOdL4ESXIzs4mMTHxAHJ3+IrHPEN85jse8wzxme+DyXP//v3nqmpapHmxrEFEOocrHo0GYX0MpwPHAh+LyOeqmgmcqqobROTIYPoyVf1svw1a4JgAkJaWpunp6VEncMaMGZRn+eogHvMM8ZnveMwzxGe+Y5XnWA7Wtw5oHfY5BdhQbJnRwBtBX0kGsBqrTaCqG4K/m4E3sSYr55xzlSSWAWI20E5E2opIHWA41pwU7gdgAICIJAMnAKtEpEHQ/ISINADOBKIcX9Q551xFiFkTk6rmisi1wIdATWCiqi4WkSuD+U8A9wLPichCrEnqNlX9SUSOAd60vmtqAS+r6gexSqtzzrn9xbIPAlWdAkwpNu2JsPcbsNpB8fVWAV1imTbnnHOl8wcGOeeci8gDhHPOuYg8QDjnnIsoZjfKVQUR2QJ8X45VmgGVOpTHISAe8wzxme94zDPEZ74PJs9tVLV5pBnVKkCUl4jMKekOwuoqHvMM8ZnveMwzxGe+Y5Vnb2JyzjkXkQcI55xzEcV7gIg4AGA1F495hvjMdzzmGeIz3zHJc1z3QTjnnCtZvNcgnHPOlcADhHPOuYjiMkCIyGARWS4iGSJye1WnJ1ZEpLWITBeRpSKyWESuD6Y3EZGPReS74O8RVZ3WiiYiNUVkvoi8G3yOhzw3FpHXRGRZ8J2fUt3zLSI3Br/tRSLybxFJqI55FpGJIrJZRBaFTSsxnyLy+6B8Wy4igw50v3EXIMKelX0W0AEYISIdqjZVMZML/I+qngicDFwT5PV2YKqqtgOmBp+rm+uBpWGf4yHPDwMfqGp7bLDLpVTjfItIK2AckKaqv8BGjR5O9czzc8DgYtMi5jP4Hx8OdAzWeSwo98ot7gIEYc/KVtV9QOhZ2dWOqv6oqvOC91lYgdEKy+/zwWLPA7+qmhTGhoikAL8Eng6bXN3z3BDoBzwDoKr7VHUH1Tzf2IjU9USkFlAfeyhZtctz8DTNbcUml5TP84HJqrpXVVcDGRzgA9fiMUC0AtaGfV4XTKvWRCQV6AbMApJV9UewIAIcWXUpi4l/ArcC+WHTqnuejwG2AM8GTWtPBw/bqrb5VtX1wHjswWM/Aj+r6kdU4zwXU1I+K6yMi8cAEc2zsqsVEUkEXgduCJ73XW2JyDnAZlWdW9VpqWS1gO7A46raDdhJ9WhaKVHQ5n4+0BZoCTQQkUuqNlWHhAor4+IxQETzrOxqQ0RqY8Fhkqq+EUzeJCItgvktgM1Vlb4YOBU4T0TWYM2Hp4vIS1TvPIP9rtep6qzg82tYwKjO+T4DWK2qW1Q1B3gD6E31znO4kvJZYWVcPAaIaJ6VXS2IPbP1GWCpqv4jbNbbwG+D978F/q+y0xYrqvp7VU1R1VTsu52mqpdQjfMMoKobgbUickIwaQCwhOqd7x+Ak0WkfvBbH4D1s1XnPIcrKZ9vA8NFpK6ItAXaAV8f0B5UNe5ewNnACmAl8IeqTk8M89kHq1p+CywIXmcDTbGrHr4L/jap6rTGKP/pwLvB+2qfZ6ArMCf4vt8Cjqju+Qb+DCwDFgEvAnWrY56Bf2P9LDlYDeGy0vIJ/CEo35YDZx3ofn2oDeeccxHFYxOTc865KHiAcM45F5EHCOeccxF5gHDOOReRBwjnnHMReYBwrgwikiciC8JeFXaHsoikho/Q6dyhpFZVJ8C5w8BuVe1a1YlwrrJ5DcK5AyQia0TkARH5OngdF0xvIyJTReTb4O/RwfRkEXlTRL4JXr2DTdUUkaeC5xp8JCL1guXHiciSYDuTqyibLo55gHCubPWKNTENC5uXqao9gX9ho8gSvH9BVTsDk4BHgumPAJ+qahdsnKTFwfR2wKOq2hHYAVwYTL8d6BZs58pYZc65kvid1M6VQUSyVTUxwvQ1wOmquioYFHGjqjYVkZ+AFqqaE0z/UVWbicgWIEVV94ZtIxX4WO2hL4jIbUBtVf2LiHwAZGPDZrylqtkxzqpzRXgNwrmDoyW8L2mZSPaGvc+jsG/wl9jTD3sAc4OH4jhXaTxAOHdwhoX9nRm8/wobSRbgYuCL4P1U4CooeGZ2w5I2KiI1gNaqOh17+FFjYL9ajHOx5GckzpWtnogsCPv8gaqGLnWtKyKzsJOtEcG0ccBEEbkFe8rb6GD69cAEEbkMqylchY3QGUlN4CURaYQ9AOYhtUeIOldpvA/CuQMU9EGkqepPVZ0W52LBm5icc85F5DUI55xzEXkNwjnnXEQeIJxzzkXkAcI551xEHiCcc85F5AHCOedcRP8fXjl3NdF/ckgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들 \n",
    "\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# 빨간 실선으로 표시\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "# 파란 실선으로 표시\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 테스트\n",
    "- 인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 32)          149184    \n",
      "_________________________________________________________________\n",
      "masking (Masking)            (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                [(None, 32), (None, 32),  8320      \n",
      "=================================================================\n",
      "Total params: 157,504\n",
      "Trainable params: 157,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 테스트\n",
    "\n",
    "- 디코더\n",
    "- 인코더와 디코더의 임베딩층은 서로 다른 임베딩 층을 사용한다\n",
    "- 디코더의 훈련과 테스트는 같은 임베딩 층을 사용한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 설계\n",
    "# 이전 시점의 상태롤 보관할 텐서\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# train 때 사용했던 임베딩 층을 재사용..\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 다음 단어 예측을 위해 이전 시점의 상태를 현 시점의 초기 상태로 사용\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "\n",
    "# 모든 시점에 대해서 단여 예측\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 정의\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <SOS>에 해당하는 정수 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = fra_to_index['<sos>']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    # 구현의 간소화를 위해서 이 함수는 배치 크기를 1로 가정합니다.\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 단어로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = index_to_fra[sampled_token_index]\n",
    "\n",
    "         # 현재 시점의 예측 단어를 예측 문장에 추가\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 정해진 길이를 넘으면 중단.\n",
    "        if (sampled_char == '<eos>' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. 모델 평가하기\n",
    "단어 단위 번역기에 대해서 훈련 데이터의 샘플과 테스트 데이터의 샘플에 대해서 번역 문장을 만들어보고 정답 문장과 번역 문장을 비교해보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과 확인을 위한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2eng(input_seq):\n",
    "    temp = ''\n",
    "    for i in input_seq :\n",
    "        if(i!=0):\n",
    "            temp = temp + index_to_eng[i] + ' '\n",
    "    return temp\n",
    "\n",
    "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2fra(input_seq):\n",
    "    temp = ''\n",
    "    for i in input_seq:\n",
    "        if ((i!=0 and i!=fra_to_index['<sos>']) and i!=fra_to_index['<eos>']):\n",
    "            temp = temp + index_to_fra[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련 데이터에 대해서 임의로 선택한 인덱스의 샘플 결과를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2436, 695, 2740, 1939, 1837, 2449, 1773, 2041, 226, 1562]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    " \n",
    "a = random.sample(range(1,3000),10) # 1부터 3000까지의 범위중에 10개를 중복없이 뽑겠다.\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 :  i struggled . \n",
      "번역문 :  j ai lutt . \n",
      "예측문 :   j ai ob je dans la v tre . \n",
      "\n",
      "\n",
      "원문 :  cut it in half . \n",
      "번역문 :  coupe le en deux . \n",
      "예측문 :   la table . \n",
      "\n",
      "\n",
      "원문 :  you re very shy . \n",
      "번역문 :  vous tes fort timide . \n",
      "예측문 :   vous tes tr s timide . \n",
      "\n",
      "\n",
      "원문 :  i m letting you go . \n",
      "번역문 :  je te lib re . \n",
      "예측문 :   je vous m en . \n",
      "\n",
      "\n",
      "원문 :  why would he lie ? \n",
      "번역문 :  pourquoi mentirait il ? \n",
      "예측문 :   pourquoi il en avait l air ? \n",
      "\n",
      "\n",
      "원문 :  it freaks me out . \n",
      "번역문 :  a me fait flipper . \n",
      "예측문 :   a me fait me . \n",
      "\n",
      "\n",
      "원문 :  we were all asleep . \n",
      "번역문 :  nous dormions tous . \n",
      "예측문 :   nous tions tous deux . \n",
      "\n",
      "\n",
      "원문 :  i m glad we saw tom . \n",
      "번역문 :  je suis content que nous ayons vu tom . \n",
      "예측문 :   je suis heureux de nous voir . \n",
      "\n",
      "\n",
      "원문 :  i took off my coat . \n",
      "번역문 :  je retirai mon manteau . \n",
      "예측문 :   je ai bu d un p chez moi . \n",
      "\n",
      "\n",
      "원문 :  don t speak so fast . \n",
      "번역문 :  ne parlez pas si vite ! \n",
      "예측문 :   ce retard ! \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in a:\n",
    "    input_seq = encoder_input_train[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    \n",
    "    print(\"원문 : \", seq2eng(encoder_input_train[seq_index]))\n",
    "    print(\"번역문 : \", seq2fra(decoder_input_train[seq_index]))\n",
    "    print(\"예측문 : \", decoded_sentence[:-5])\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트용 디코더 모델이 정상적으로 만들어져서, 정답과 어느정도 유사한 프랑스어 번역이 진행되었는지 확인\n",
    "\n",
    "- 구글 번역기를 통해서 확인해 보았습니다. \n",
    "\n",
    "![title](./Google_Transfer.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평가 루브릭\n",
    "\n",
    "- 아래의 기준을 바탕으로 프로젝트를 평가합니다.\n",
    "\n",
    "1. 번역기 모델 학습에 필요한 텍스트 데이터 전처리가 잘 이루어졌다. :  구두점, 대소문자, 띄어쓰기 등 번역기 모델에 요구되는 전처리가 정상적으로 진행되었다.\n",
    "2. seq2seq 기반의 번역기 모델이 정상적으로 구동된다. :  seq2seq 모델 훈련결과 validation loss가 안정적으로 떨어지면서 학습이 진행됨이 확인되었다.\n",
    "3. 테스트 결과 의미가 통하는 수준의 번역문이 생성되었다. : 테스트용 디코더 모델이 정상적으로 만들어져서, 정답과 어느정도 유사한 프랑스어 번역이 진행됨을 확인하였다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
